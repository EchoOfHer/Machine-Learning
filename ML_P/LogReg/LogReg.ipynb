{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "737ed0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (16720, 89)\n",
      "Testing features shape: (4180, 89)\n",
      "\n",
      "Training the model...\n",
      "Model training complete!\n",
      "\n",
      "Model Accuracy on Test Data: 81.94%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8405    0.8485    0.8445      2416\n",
      "         1.0     0.7898    0.7795    0.7846      1764\n",
      "\n",
      "    accuracy                         0.8194      4180\n",
      "   macro avg     0.8151    0.8140    0.8145      4180\n",
      "weighted avg     0.8191    0.8194    0.8192      4180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# --- Step 1: Load Your PROCESSED Data ---\n",
    "# We use the clean CSVs you just saved\n",
    "try:\n",
    "    train_df = pd.read_csv('../data/salary.train.processed.csv', index_col='id')\n",
    "    test_df = pd.read_csv('../data/salary.test.processed.csv', index_col='id')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Could not find the processed CSV files.\")\n",
    "    print(\"Please make sure 'salary.train.processed.csv' and 'salary.test.processed.csv' are in the './data/' folder.\")\n",
    "    # Stop here if files aren't found\n",
    "    raise\n",
    "    \n",
    "\n",
    "# --- Step 2: Separate Features (X) and Target (y) ---\n",
    "# The 'label' column is our target (y)\n",
    "# All other columns are our features (X)\n",
    "\n",
    "# Training data\n",
    "X_train = train_df.drop('label', axis=1)\n",
    "y_train = train_df['label']\n",
    "\n",
    "# Test data\n",
    "X_test = test_df.drop('label', axis=1)\n",
    "y_test = test_df['label']\n",
    "\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Testing features shape: {X_test.shape}\")\n",
    "\n",
    "\n",
    "# --- Step 3: Initialize and Train the Model ---\n",
    "# We add max_iter=1000 to help the model solve for the best fit\n",
    "# 'random_state=42' just ensures you get the same result as me\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "print(\"\\nTraining the model...\")\n",
    "log_reg.fit(X_train, y_train)\n",
    "print(\"Model training complete!\")\n",
    "\n",
    "\n",
    "# --- Step 4: Evaluate the Model ---\n",
    "# Make predictions on the (unseen) test data\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Check the accuracy\n",
    "# This tells us what percentage of predictions were correct\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy on Test Data: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Get a detailed report (precision, recall, f1-score)\n",
    "# This is much more useful than just accuracy\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6fd41829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:55:23,244] A new study created in memory with name: no-name-17991bf4-de1c-424c-9319-79f3eb1cb23a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ใช้ข้อมูลเทรนทั้งหมด 16720 records สำหรับการจูน (K-Fold CV)\n",
      "\n",
      "กำลังเริ่มการค้นหาพารามิเตอร์สำหรับ Logistic Regression ด้วย Optuna...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49ac1994e5243a6a212ee0ece74067b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:55:32,933] Trial 0 finished with value: 0.8132164063781692 and parameters: {'C': 3.5518274294091126, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:55:37,781] Trial 1 finished with value: 0.809392227702531 and parameters: {'C': 0.005018906875357333, 'penalty': 'elasticnet', 'l1_ratio': 0.5420208302897495}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:55:44,454] Trial 2 finished with value: 0.8129823272647618 and parameters: {'C': 0.12343627546992857, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:55:45,625] Trial 3 finished with value: 0.8102552199537056 and parameters: {'C': 0.003933986242833884, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:55:53,683] Trial 4 finished with value: 0.8132164063781692 and parameters: {'C': 81.54029874770107, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:56:02,111] Trial 5 finished with value: 0.8131576137649511 and parameters: {'C': 8.061837050428842, 'penalty': 'elasticnet', 'l1_ratio': 0.22058217652912182}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:56:11,632] Trial 6 finished with value: 0.8131576137649511 and parameters: {'C': 16.623305601598723, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:56:12,225] Trial 7 finished with value: 0.8017405628649449 and parameters: {'C': 0.0006098318334816925, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:56:13,258] Trial 8 finished with value: 0.7826652869626302 and parameters: {'C': 0.0010519122143577884, 'penalty': 'elasticnet', 'l1_ratio': 0.5972191915105932}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:56:35,904] Trial 9 finished with value: 0.8123936167377316 and parameters: {'C': 0.1927454662931631, 'penalty': 'elasticnet', 'l1_ratio': 0.6746204657451131}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:56:43,063] Trial 10 finished with value: 0.8131587144567263 and parameters: {'C': 1.3343332226034132, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:56:51,596] Trial 11 finished with value: 0.8132164063781692 and parameters: {'C': 96.61614710106187, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:56:59,950] Trial 12 finished with value: 0.8132164063781692 and parameters: {'C': 74.48385233548599, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:57:26,799] Trial 13 finished with value: 0.813039829316265 and parameters: {'C': 1.754380822215291, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:57:33,231] Trial 14 finished with value: 0.8132164063781692 and parameters: {'C': 3.422477636816296, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:57:57,719] Trial 15 finished with value: 0.8125673231384845 and parameters: {'C': 0.4194043861057135, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:58:05,881] Trial 16 finished with value: 0.8131576137649511 and parameters: {'C': 21.440037703707368, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:58:08,406] Trial 17 finished with value: 0.8118770469709821 and parameters: {'C': 0.01932714667974294, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:58:14,723] Trial 18 finished with value: 0.8132164063781692 and parameters: {'C': 29.180430640421683, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:58:51,192] Trial 19 finished with value: 0.8125073000145792 and parameters: {'C': 0.6215275430178784, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:58:58,754] Trial 20 finished with value: 0.8132164063781692 and parameters: {'C': 4.43569821487827, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:59:14,693] Trial 21 finished with value: 0.8132164063781692 and parameters: {'C': 90.35598101668857, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:59:15,070] Trial 22 finished with value: 0.36729968078394726 and parameters: {'C': 0.00011731861839128305, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:59:31,000] Trial 23 finished with value: 0.8132164063781692 and parameters: {'C': 97.80707951290442, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:59:47,949] Trial 24 finished with value: 0.8131576137649511 and parameters: {'C': 11.670962348426867, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:59:58,380] Trial 25 finished with value: 0.8132164063781692 and parameters: {'C': 36.431305095145184, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:00:07,386] Trial 26 finished with value: 0.8130386896924887 and parameters: {'C': 6.5474429057482615, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:00:13,292] Trial 27 finished with value: 0.8117701468338122 and parameters: {'C': 0.04229887355720717, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:00:23,027] Trial 28 finished with value: 0.8132164063781692 and parameters: {'C': 38.59953996851596, 'penalty': 'elasticnet', 'l1_ratio': 0.962702257592092}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:00:30,912] Trial 29 finished with value: 0.8130988182429312 and parameters: {'C': 1.814161690655077, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:00:39,412] Trial 30 finished with value: 0.8129798941704688 and parameters: {'C': 0.501243277400418, 'penalty': 'elasticnet', 'l1_ratio': 0.022072489733639955}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:00:48,095] Trial 31 finished with value: 0.8132164063781692 and parameters: {'C': 78.02547415516875, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:00:56,770] Trial 32 finished with value: 0.8132164063781692 and parameters: {'C': 43.004869380040134, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:01:05,355] Trial 33 finished with value: 0.8131576137649511 and parameters: {'C': 12.085144398203203, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:01:14,348] Trial 34 finished with value: 0.8132164063781692 and parameters: {'C': 50.84496701548842, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:01:22,358] Trial 35 finished with value: 0.8132164063781692 and parameters: {'C': 19.734002900766917, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:01:31,664] Trial 36 finished with value: 0.8130386896924887 and parameters: {'C': 4.282569337908345, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:01:41,311] Trial 37 finished with value: 0.8132164063781692 and parameters: {'C': 9.367323608323172, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:01:49,496] Trial 38 finished with value: 0.8132164063781692 and parameters: {'C': 89.76573552622838, 'penalty': 'elasticnet', 'l1_ratio': 0.998468403898508}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:01:57,142] Trial 39 finished with value: 0.8131576137649511 and parameters: {'C': 20.756457603908228, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:02:03,619] Trial 40 finished with value: 0.8132164063781692 and parameters: {'C': 2.4639102235000387, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:02:11,108] Trial 41 finished with value: 0.8129812868585246 and parameters: {'C': 0.24505661183306035, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:02:15,921] Trial 42 finished with value: 0.8128630333684274 and parameters: {'C': 0.0805929156592984, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:02:24,682] Trial 43 finished with value: 0.813039786194267 and parameters: {'C': 0.9370146046931824, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:02:26,496] Trial 44 finished with value: 0.8103549593281606 and parameters: {'C': 0.006731947649356776, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:02:33,194] Trial 45 finished with value: 0.8132164063781692 and parameters: {'C': 4.055126712145577, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:02:42,349] Trial 46 finished with value: 0.8131576137649511 and parameters: {'C': 7.534141298630893, 'penalty': 'elasticnet', 'l1_ratio': 0.3037998201948257}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:02:52,455] Trial 47 finished with value: 0.8132164063781692 and parameters: {'C': 51.618415321449575, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:03:02,450] Trial 48 finished with value: 0.8132164063781692 and parameters: {'C': 22.171311920429652, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:03:12,245] Trial 49 finished with value: 0.8130985817162869 and parameters: {'C': 3.2811192709186914, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "\n",
      "--- Optuna ค้นหาเสร็จสิ้น! ---\n",
      "พารามิเตอร์ที่ดีที่สุด (Best Parameters):\n",
      "{'C': 3.5518274294091126, 'penalty': 'l2'}\n",
      "\n",
      "F1-Weighted ที่ดีที่สุด (จากการ CV): 0.813216\n",
      "\n",
      "กำลังเทรน Pipeline สุดท้ายด้วยพารามิเตอร์ที่ดีที่สุด...\n",
      "เทรนโมเดลสุดท้ายเสร็จสิ้น! กำลังประเมินผลบน Test Set...\n",
      "\n",
      "Logistic Regression (Optuna-Tuned) Confusion Matrix:\n",
      "[[1937  479]\n",
      " [ 280 1484]]\n",
      "\n",
      "Logistic Regression (Optuna-Tuned) Report:\n",
      "              precision    recall  f1-score      support\n",
      "0.0            0.873703  0.801738  0.836175  2416.000000\n",
      "1.0            0.755986  0.841270  0.796351  1764.000000\n",
      "accuracy       0.818421  0.818421  0.818421     0.818421\n",
      "macro avg      0.814844  0.821504  0.816263  4180.000000\n",
      "weighted avg   0.824025  0.818421  0.819369  4180.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import optuna\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline # 👈 สำคัญมาก\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# --- 1. โหลดข้อมูล (เหมือนเดิม) ---\n",
    "try:\n",
    "    data_train_full = pandas.read_csv('../data/salary.train.processed.csv').set_index('id')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: ไม่พบไฟล์ salary.train.processed.csv กรุณาตรวจสอบ path\")\n",
    "    # exit() \n",
    "\n",
    "X_full = data_train_full.drop(['label'], axis='columns')\n",
    "y_full = data_train_full['label']\n",
    "\n",
    "print(f\"ใช้ข้อมูลเทรนทั้งหมด {len(y_full)} records สำหรับการจูน (K-Fold CV)\")\n",
    "\n",
    "\n",
    "# --- 2. สร้างฟังก์ชัน Objective (หัวใจของ Optuna) ---\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    ฟังก์ชันนี้จะถูกเรียกโดย Optuna ในแต่ละ \"trial\" (การทดลอง)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. กำหนดช่วงของพารามิเตอร์\n",
    "    \n",
    "    # C (Regularization strength) - สุ่มแบบ log (1e-4 ถึง 1e2)\n",
    "    C = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
    "    \n",
    "    # Penalty - 'saga' solver รองรับทั้งหมด\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet'])\n",
    "    \n",
    "    # l1_ratio - จะถูกใช้ *ต่อเมื่อ* penalty เป็น 'elasticnet'\n",
    "    l1_ratio = None\n",
    "    if penalty == 'elasticnet':\n",
    "        l1_ratio = trial.suggest_float('l1_ratio', 0, 1)\n",
    "\n",
    "    \n",
    "    # 2. สร้าง Pipeline ที่รวม Scaler และ Model เข้าด้วยกัน\n",
    "    pipeline_lr = Pipeline([\n",
    "        ('scaler', StandardScaler()), # ขั้นตอนที่ 1: ปรับสเกลข้อมูล\n",
    "        ('model', LogisticRegression(   # ขั้นตอนที่ 2: เทรนโมเดล\n",
    "            C=C,\n",
    "            penalty=penalty,\n",
    "            l1_ratio=l1_ratio,\n",
    "            solver='saga',         # 'saga' รองรับทุก penalty\n",
    "            class_weight='balanced', # จัดการ imbalance\n",
    "            random_state=42,\n",
    "            max_iter=5000,         # 'saga' อาจต้องใช้ iter เยอะหน่อย\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # 3. ประเมินผล Pipeline ด้วย Cross-validation\n",
    "    score = cross_val_score(\n",
    "        pipeline_lr, # 👈 ใช้ pipeline แทน model ตรงๆ\n",
    "        X_full, \n",
    "        y_full, \n",
    "        cv=3,                 \n",
    "        scoring='f1_weighted',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # 4. คืนค่า F1 เฉลี่ยกลับไปให้ Optuna\n",
    "    f1_avg = np.mean(score)\n",
    "    return f1_avg\n",
    "\n",
    "# --- 3. เริ่มการค้นหา (Study) ---\n",
    "\n",
    "print(\"\\nกำลังเริ่มการค้นหาพารามิเตอร์สำหรับ Logistic Regression ด้วย Optuna...\")\n",
    "\n",
    "# สร้าง study object, บอกว่าเราต้องการ 'maximize' (หาค่า F1 สูงสุด)\n",
    "pruner = optuna.pruners.MedianPruner()\n",
    "study = optuna.create_study(direction='maximize', pruner=pruner)\n",
    "\n",
    "# สั่งให้เริ่มค้นหา (optimize) 50 ครั้ง\n",
    "study.optimize(\n",
    "    objective, \n",
    "    n_trials=50, \n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# --- 4. แสดงผลลัพธ์ ---\n",
    "\n",
    "print(\"\\n--- Optuna ค้นหาเสร็จสิ้น! ---\")\n",
    "\n",
    "print(\"พารามิเตอร์ที่ดีที่สุด (Best Parameters):\")\n",
    "print(study.best_params)\n",
    "print(f\"\\nF1-Weighted ที่ดีที่สุด (จากการ CV): {study.best_value:.6f}\")\n",
    "\n",
    "\n",
    "# --- 5. (ขั้นตอนต่อไป) เทรนโมเดลสุดท้ายและประเมินผลบน Test Set ---\n",
    "\n",
    "print(\"\\nกำลังเทรน Pipeline สุดท้ายด้วยพารามิเตอร์ที่ดีที่สุด...\")\n",
    "\n",
    "# ดึงพารามิเตอร์ที่ดีที่สุดมา\n",
    "best_lr_params = study.best_params\n",
    "\n",
    "# สร้าง Pipeline สุดท้าย (ต้องมี scaler ด้วย)\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression(\n",
    "        C=best_lr_params.get('C'),\n",
    "        penalty=best_lr_params.get('penalty'),\n",
    "        l1_ratio=best_lr_params.get('l1_ratio'), # จะเป็น None ถ้า penalty ไม่ใช่ 'elasticnet'\n",
    "        solver='saga',\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        max_iter=5000,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# เทรน Pipeline สุดท้ายด้วยข้อมูล \"ทั้งหมด\" (X_full, y_full)\n",
    "final_pipeline.fit(X_full, y_full)\n",
    "\n",
    "print(\"เทรนโมเดลสุดท้ายเสร็จสิ้น! กำลังประเมินผลบน Test Set...\")\n",
    "\n",
    "# โหลดข้อมูล Test\n",
    "data_test_lr = pandas.read_csv('../data/salary.test.processed.csv').set_index('id')\n",
    "\n",
    "# ทำนายผลด้วย Pipeline (มันจะ scale และ predict ให้อัตโนมัติ)\n",
    "data_test_lr['prediction'] = final_pipeline.predict(data_test_lr.drop(['label'], axis='columns'))\n",
    "\n",
    "# แสดงผลลัพธ์บน Test Set\n",
    "print(\"\\nLogistic Regression (Optuna-Tuned) Confusion Matrix:\")\n",
    "print(sklearn.metrics.confusion_matrix(\n",
    "    y_true=data_test_lr['label'],\n",
    "    y_pred=data_test_lr['prediction']\n",
    "))\n",
    "\n",
    "report_scores_lr = sklearn.metrics.classification_report(\n",
    "    y_true=data_test_lr['label'],\n",
    "    y_pred=data_test_lr['prediction'],\n",
    "    digits=6,\n",
    "    output_dict=True\n",
    ")\n",
    "df_score_lr = pandas.DataFrame(report_scores_lr).transpose()\n",
    "print(\"\\nLogistic Regression (Optuna-Tuned) Report:\")\n",
    "print(df_score_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "58204a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'C': 3.5518274294091126, \n",
    "    'penalty': 'l2', \n",
    "    # 'l1_ratio': 0.349891944349909\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c40209",
   "metadata": {},
   "source": [
    "### Class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4e449d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Testing LogReg with Class Weight ---\n",
      "Model training complete.\n",
      "\n",
      "LogReg (Tuned + Class Weight) Report:\n",
      "              precision    recall  f1-score      support\n",
      "0.0            0.873703  0.801738  0.836175  2416.000000\n",
      "1.0            0.755986  0.841270  0.796351  1764.000000\n",
      "accuracy       0.818421  0.818421  0.818421     0.818421\n",
      "macro avg      0.814844  0.821504  0.816263  4180.000000\n",
      "weighted avg   0.824025  0.818421  0.819369  4180.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "print(\"--- 1. Testing LogReg with Class Weight ---\")\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    data_train_full = pandas.read_csv('../data/salary.train.processed.csv').set_index('id')\n",
    "    data_test_lr = pandas.read_csv('../data/salary.test.processed.csv').set_index('id')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: ไม่พบไฟล์ salary.train.processed.csv กรุณาตรวจสอบ path\")\n",
    "    # exit() \n",
    "\n",
    "X_full = data_train_full.drop(['label'], axis='columns')\n",
    "y_full = data_train_full['label']\n",
    "X_test = data_test_lr.drop(['label'], axis='columns')\n",
    "y_test = data_test_lr['label']\n",
    "\n",
    "# --- Define Parameters ---\n",
    "best_lr_params = best_params\n",
    "# --- Create and Train Pipeline ---\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), # Step 1: Scale\n",
    "    ('model', LogisticRegression(\n",
    "        **best_lr_params,\n",
    "        class_weight='balanced', # 👈 Add weight\n",
    "        solver='saga',\n",
    "        max_iter=5000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_full, y_full) # Train on original data\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# --- Evaluate ---\n",
    "y_pred = pipeline.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, digits=6, output_dict=True)\n",
    "df_report = pandas.DataFrame(report).transpose()\n",
    "\n",
    "print(\"\\nLogReg (Tuned + Class Weight) Report:\")\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fc4476",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "12d14bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. Testing LogReg with SMOTE ---\n",
      "Applying SMOTE...\n",
      "New resampled label distribution:\n",
      "label\n",
      "1.0    9719\n",
      "0.0    9719\n",
      "Name: count, dtype: int64\n",
      "Model training complete.\n",
      "\n",
      "LogReg (Tuned + SMOTE) Report:\n",
      "              precision    recall  f1-score      support\n",
      "0.0            0.874322  0.800497  0.835782  2416.000000\n",
      "1.0            0.755081  0.842404  0.796356  1764.000000\n",
      "accuracy       0.818182  0.818182  0.818182     0.818182\n",
      "macro avg      0.814702  0.821450  0.816069  4180.000000\n",
      "weighted avg   0.824001  0.818182  0.819144  4180.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(\"\\n--- 2. Testing LogReg with SMOTE ---\")\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    data_train_full = pandas.read_csv('../data/salary.train.processed.csv').set_index('id')\n",
    "    data_test_lr = pandas.read_csv('../data/salary.test.processed.csv').set_index('id')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: ไม่พบไฟล์ salary.train.processed.csv กรุณาตรวจสอบ path\")\n",
    "    # exit() \n",
    "\n",
    "X_full = data_train_full.drop(['label'], axis='columns')\n",
    "y_full = data_train_full['label']\n",
    "X_test = data_test_lr.drop(['label'], axis='columns')\n",
    "y_test = data_test_lr['label']\n",
    "\n",
    "# --- Apply SMOTE ---\n",
    "print(\"Applying SMOTE...\")\n",
    "smote = SMOTE(random_state=42, n_jobs=-1)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_full, y_full)\n",
    "print(f\"New resampled label distribution:\\n{y_resampled.value_counts()}\")\n",
    "\n",
    "# --- Define Parameters ---\n",
    "best_lr_params = best_params\n",
    "\n",
    "# --- Create and Train Pipeline ---\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), # Step 1: Scale\n",
    "    ('model', LogisticRegression(\n",
    "        **best_lr_params,\n",
    "        # ⚠️ NO 'class_weight'\n",
    "        solver='saga',\n",
    "        max_iter=5000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_resampled, y_resampled) # Train on SMOTEd data\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# --- Evaluate ---\n",
    "y_pred = pipeline.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, digits=6, output_dict=True)\n",
    "df_report = pandas.DataFrame(report).transpose()\n",
    "\n",
    "print(\"\\nLogReg (Tuned + SMOTE) Report:\")\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa13b70",
   "metadata": {},
   "source": [
    "### SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "465dfea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. Testing LogReg with SMOTETomek ---\n",
      "Applying SMOTETomek...\n",
      "New resampled label distribution:\n",
      "label\n",
      "1.0    8914\n",
      "0.0    8914\n",
      "Name: count, dtype: int64\n",
      "Model training complete.\n",
      "\n",
      "LogReg (Tuned + SMOTETomek) Report:\n",
      "              precision    recall  f1-score      support\n",
      "0.0            0.881084  0.794288  0.835438  2416.000000\n",
      "1.0            0.751748  0.853175  0.799257  1764.000000\n",
      "accuracy       0.819139  0.819139  0.819139     0.819139\n",
      "macro avg      0.816416  0.823731  0.817347  4180.000000\n",
      "weighted avg   0.826503  0.819139  0.820169  4180.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "print(\"\\n--- 3. Testing LogReg with SMOTETomek ---\")\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    data_train_full = pandas.read_csv('../data/salary.train.processed.csv').set_index('id')\n",
    "    data_test_lr = pandas.read_csv('../data/salary.test.processed.csv').set_index('id')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: ไม่พบไฟล์ salary.train.processed.csv กรุณาตรวจสอบ path\")\n",
    "    # exit() \n",
    "\n",
    "X_full = data_train_full.drop(['label'], axis='columns')\n",
    "y_full = data_train_full['label']\n",
    "X_test = data_test_lr.drop(['label'], axis='columns')\n",
    "y_test = data_test_lr['label']\n",
    "\n",
    "# --- Apply SMOTETomek ---\n",
    "print(\"Applying SMOTETomek...\")\n",
    "smt = SMOTETomek(random_state=42, n_jobs=-1)\n",
    "X_resampled, y_resampled = smt.fit_resample(X_full, y_full)\n",
    "print(f\"New resampled label distribution:\\n{y_resampled.value_counts()}\")\n",
    "\n",
    "# --- Define Parameters ---\n",
    "best_lr_params = best_params\n",
    "\n",
    "# --- Create and Train Pipeline ---\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), # Step 1: Scale\n",
    "    ('model', LogisticRegression(\n",
    "        **best_lr_params,\n",
    "        # ⚠️ NO 'class_weight'\n",
    "        solver='saga',\n",
    "        max_iter=5000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_resampled, y_resampled) # Train on SMOTETomek data\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# --- Evaluate ---\n",
    "y_pred = pipeline.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, digits=6, output_dict=True)\n",
    "df_report = pandas.DataFrame(report).transpose()\n",
    "\n",
    "print(\"\\nLogReg (Tuned + SMOTETomek) Report:\")\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846f4864",
   "metadata": {},
   "source": [
    "### ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0df67c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4. Testing LogReg with ADASYN ---\n",
      "Error: ไม่พบไฟล์ salary.train.processed.csv กรุณาตรวจสอบ path\n",
      "Applying ADASYN...\n",
      "New resampled label distribution:\n",
      "label\n",
      "1.0    9726\n",
      "0.0    9719\n",
      "Name: count, dtype: int64\n",
      "Model training complete.\n",
      "\n",
      "LogReg (Tuned + ADASYN) Report:\n",
      "              precision    recall  f1-score      support\n",
      "0.0            0.892278  0.774834  0.829420  2416.000000\n",
      "1.0            0.738713  0.871882  0.799792  1764.000000\n",
      "accuracy       0.815789  0.815789  0.815789     0.815789\n",
      "macro avg      0.815496  0.823358  0.814606  4180.000000\n",
      "weighted avg   0.827472  0.815789  0.816916  4180.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "print(\"\\n--- 4. Testing LogReg with ADASYN ---\")\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    data_train_full = pandas.read_csv('./data/salary.train.processed.csv').set_index('id')\n",
    "    data_test_lr = pandas.read_csv('./data/salary.test.processed.csv').set_index('id')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: ไม่พบไฟล์ salary.train.processed.csv กรุณาตรวจสอบ path\")\n",
    "    # exit() \n",
    "\n",
    "X_full = data_train_full.drop(['label'], axis='columns')\n",
    "y_full = data_train_full['label']\n",
    "X_test = data_test_lr.drop(['label'], axis='columns')\n",
    "y_test = data_test_lr['label']\n",
    "\n",
    "# --- Apply ADASYN ---\n",
    "print(\"Applying ADASYN...\")\n",
    "ada = ADASYN(random_state=42, n_jobs=-1)\n",
    "X_resampled, y_resampled = ada.fit_resample(X_full, y_full)\n",
    "print(f\"New resampled label distribution:\\n{y_resampled.value_counts()}\")\n",
    "\n",
    "# --- Define Parameters ---\n",
    "best_lr_params = best_params\n",
    "\n",
    "# --- Create and Train Pipeline ---\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), # Step 1: Scale\n",
    "    ('model', LogisticRegression(\n",
    "        **best_lr_params,\n",
    "        # ⚠️ NO 'class_weight'\n",
    "        solver='saga',\n",
    "        max_iter=5000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_resampled, y_resampled) # Train on ADASYN data\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# --- Evaluate ---\n",
    "y_pred = pipeline.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, digits=6, output_dict=True)\n",
    "df_report = pandas.DataFrame(report).transpose()\n",
    "\n",
    "print(\"\\nLogReg (Tuned + ADASYN) Report:\")\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f480b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
