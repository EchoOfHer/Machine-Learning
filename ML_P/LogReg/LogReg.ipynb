{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "737ed0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (16720, 89)\n",
      "Testing features shape: (4180, 89)\n",
      "\n",
      "Training the model...\n",
      "Model training complete!\n",
      "\n",
      "Model Accuracy on Test Data: 81.94%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8405    0.8485    0.8445      2416\n",
      "         1.0     0.7898    0.7795    0.7846      1764\n",
      "\n",
      "    accuracy                         0.8194      4180\n",
      "   macro avg     0.8151    0.8140    0.8145      4180\n",
      "weighted avg     0.8191    0.8194    0.8192      4180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# --- Step 1: Load Your PROCESSED Data ---\n",
    "# We use the clean CSVs you just saved\n",
    "try:\n",
    "    train_df = pd.read_csv('../data/salary.train.processed.csv', index_col='id')\n",
    "    test_df = pd.read_csv('../data/salary.test.processed.csv', index_col='id')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Could not find the processed CSV files.\")\n",
    "    print(\"Please make sure 'salary.train.processed.csv' and 'salary.test.processed.csv' are in the './data/' folder.\")\n",
    "    # Stop here if files aren't found\n",
    "    raise\n",
    "    \n",
    "\n",
    "# --- Step 2: Separate Features (X) and Target (y) ---\n",
    "# The 'label' column is our target (y)\n",
    "# All other columns are our features (X)\n",
    "\n",
    "# Training data\n",
    "X_train = train_df.drop('label', axis=1)\n",
    "y_train = train_df['label']\n",
    "\n",
    "# Test data\n",
    "X_test = test_df.drop('label', axis=1)\n",
    "y_test = test_df['label']\n",
    "\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Testing features shape: {X_test.shape}\")\n",
    "\n",
    "\n",
    "# --- Step 3: Initialize and Train the Model ---\n",
    "# We add max_iter=1000 to help the model solve for the best fit\n",
    "# 'random_state=42' just ensures you get the same result as me\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "print(\"\\nTraining the model...\")\n",
    "log_reg.fit(X_train, y_train)\n",
    "print(\"Model training complete!\")\n",
    "\n",
    "\n",
    "# --- Step 4: Evaluate the Model ---\n",
    "# Make predictions on the (unseen) test data\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Check the accuracy\n",
    "# This tells us what percentage of predictions were correct\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy on Test Data: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Get a detailed report (precision, recall, f1-score)\n",
    "# This is much more useful than just accuracy\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6fd41829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:55:23,244] A new study created in memory with name: no-name-17991bf4-de1c-424c-9319-79f3eb1cb23a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏£‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î 16720 records ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏π‡∏ô (K-Fold CV)\n",
      "\n",
      "‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Logistic Regression ‡∏î‡πâ‡∏ß‡∏¢ Optuna...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49ac1994e5243a6a212ee0ece74067b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:55:32,933] Trial 0 finished with value: 0.8132164063781692 and parameters: {'C': 3.5518274294091126, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:55:37,781] Trial 1 finished with value: 0.809392227702531 and parameters: {'C': 0.005018906875357333, 'penalty': 'elasticnet', 'l1_ratio': 0.5420208302897495}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:55:44,454] Trial 2 finished with value: 0.8129823272647618 and parameters: {'C': 0.12343627546992857, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:55:45,625] Trial 3 finished with value: 0.8102552199537056 and parameters: {'C': 0.003933986242833884, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:55:53,683] Trial 4 finished with value: 0.8132164063781692 and parameters: {'C': 81.54029874770107, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:56:02,111] Trial 5 finished with value: 0.8131576137649511 and parameters: {'C': 8.061837050428842, 'penalty': 'elasticnet', 'l1_ratio': 0.22058217652912182}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:56:11,632] Trial 6 finished with value: 0.8131576137649511 and parameters: {'C': 16.623305601598723, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:56:12,225] Trial 7 finished with value: 0.8017405628649449 and parameters: {'C': 0.0006098318334816925, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:56:13,258] Trial 8 finished with value: 0.7826652869626302 and parameters: {'C': 0.0010519122143577884, 'penalty': 'elasticnet', 'l1_ratio': 0.5972191915105932}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:56:35,904] Trial 9 finished with value: 0.8123936167377316 and parameters: {'C': 0.1927454662931631, 'penalty': 'elasticnet', 'l1_ratio': 0.6746204657451131}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:56:43,063] Trial 10 finished with value: 0.8131587144567263 and parameters: {'C': 1.3343332226034132, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:56:51,596] Trial 11 finished with value: 0.8132164063781692 and parameters: {'C': 96.61614710106187, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:56:59,950] Trial 12 finished with value: 0.8132164063781692 and parameters: {'C': 74.48385233548599, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:57:26,799] Trial 13 finished with value: 0.813039829316265 and parameters: {'C': 1.754380822215291, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:57:33,231] Trial 14 finished with value: 0.8132164063781692 and parameters: {'C': 3.422477636816296, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:57:57,719] Trial 15 finished with value: 0.8125673231384845 and parameters: {'C': 0.4194043861057135, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:58:05,881] Trial 16 finished with value: 0.8131576137649511 and parameters: {'C': 21.440037703707368, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:58:08,406] Trial 17 finished with value: 0.8118770469709821 and parameters: {'C': 0.01932714667974294, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:58:14,723] Trial 18 finished with value: 0.8132164063781692 and parameters: {'C': 29.180430640421683, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:58:51,192] Trial 19 finished with value: 0.8125073000145792 and parameters: {'C': 0.6215275430178784, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:58:58,754] Trial 20 finished with value: 0.8132164063781692 and parameters: {'C': 4.43569821487827, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:59:14,693] Trial 21 finished with value: 0.8132164063781692 and parameters: {'C': 90.35598101668857, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:59:15,070] Trial 22 finished with value: 0.36729968078394726 and parameters: {'C': 0.00011731861839128305, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:59:31,000] Trial 23 finished with value: 0.8132164063781692 and parameters: {'C': 97.80707951290442, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:59:47,949] Trial 24 finished with value: 0.8131576137649511 and parameters: {'C': 11.670962348426867, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 19:59:58,380] Trial 25 finished with value: 0.8132164063781692 and parameters: {'C': 36.431305095145184, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:00:07,386] Trial 26 finished with value: 0.8130386896924887 and parameters: {'C': 6.5474429057482615, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:00:13,292] Trial 27 finished with value: 0.8117701468338122 and parameters: {'C': 0.04229887355720717, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:00:23,027] Trial 28 finished with value: 0.8132164063781692 and parameters: {'C': 38.59953996851596, 'penalty': 'elasticnet', 'l1_ratio': 0.962702257592092}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:00:30,912] Trial 29 finished with value: 0.8130988182429312 and parameters: {'C': 1.814161690655077, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:00:39,412] Trial 30 finished with value: 0.8129798941704688 and parameters: {'C': 0.501243277400418, 'penalty': 'elasticnet', 'l1_ratio': 0.022072489733639955}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:00:48,095] Trial 31 finished with value: 0.8132164063781692 and parameters: {'C': 78.02547415516875, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:00:56,770] Trial 32 finished with value: 0.8132164063781692 and parameters: {'C': 43.004869380040134, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:01:05,355] Trial 33 finished with value: 0.8131576137649511 and parameters: {'C': 12.085144398203203, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:01:14,348] Trial 34 finished with value: 0.8132164063781692 and parameters: {'C': 50.84496701548842, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:01:22,358] Trial 35 finished with value: 0.8132164063781692 and parameters: {'C': 19.734002900766917, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:01:31,664] Trial 36 finished with value: 0.8130386896924887 and parameters: {'C': 4.282569337908345, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:01:41,311] Trial 37 finished with value: 0.8132164063781692 and parameters: {'C': 9.367323608323172, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:01:49,496] Trial 38 finished with value: 0.8132164063781692 and parameters: {'C': 89.76573552622838, 'penalty': 'elasticnet', 'l1_ratio': 0.998468403898508}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:01:57,142] Trial 39 finished with value: 0.8131576137649511 and parameters: {'C': 20.756457603908228, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:02:03,619] Trial 40 finished with value: 0.8132164063781692 and parameters: {'C': 2.4639102235000387, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:02:11,108] Trial 41 finished with value: 0.8129812868585246 and parameters: {'C': 0.24505661183306035, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:02:15,921] Trial 42 finished with value: 0.8128630333684274 and parameters: {'C': 0.0805929156592984, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:02:24,682] Trial 43 finished with value: 0.813039786194267 and parameters: {'C': 0.9370146046931824, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:02:26,496] Trial 44 finished with value: 0.8103549593281606 and parameters: {'C': 0.006731947649356776, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:02:33,194] Trial 45 finished with value: 0.8132164063781692 and parameters: {'C': 4.055126712145577, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:02:42,349] Trial 46 finished with value: 0.8131576137649511 and parameters: {'C': 7.534141298630893, 'penalty': 'elasticnet', 'l1_ratio': 0.3037998201948257}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:02:52,455] Trial 47 finished with value: 0.8132164063781692 and parameters: {'C': 51.618415321449575, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:03:02,450] Trial 48 finished with value: 0.8132164063781692 and parameters: {'C': 22.171311920429652, 'penalty': 'l2'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "[I 2025-10-21 20:03:12,245] Trial 49 finished with value: 0.8130985817162869 and parameters: {'C': 3.2811192709186914, 'penalty': 'l1'}. Best is trial 0 with value: 0.8132164063781692.\n",
      "\n",
      "--- Optuna ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ---\n",
      "‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (Best Parameters):\n",
      "{'C': 3.5518274294091126, 'penalty': 'l2'}\n",
      "\n",
      "F1-Weighted ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£ CV): 0.813216\n",
      "\n",
      "‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô Pipeline ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î...\n",
      "‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏ö‡∏ô Test Set...\n",
      "\n",
      "Logistic Regression (Optuna-Tuned) Confusion Matrix:\n",
      "[[1937  479]\n",
      " [ 280 1484]]\n",
      "\n",
      "Logistic Regression (Optuna-Tuned) Report:\n",
      "              precision    recall  f1-score      support\n",
      "0.0            0.873703  0.801738  0.836175  2416.000000\n",
      "1.0            0.755986  0.841270  0.796351  1764.000000\n",
      "accuracy       0.818421  0.818421  0.818421     0.818421\n",
      "macro avg      0.814844  0.821504  0.816263  4180.000000\n",
      "weighted avg   0.824025  0.818421  0.819369  4180.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import optuna\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline # üëà ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# --- 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ---\n",
    "try:\n",
    "    data_train_full = pandas.read_csv('../data/salary.train.processed.csv').set_index('id')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå salary.train.processed.csv ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path\")\n",
    "    # exit() \n",
    "\n",
    "X_full = data_train_full.drop(['label'], axis='columns')\n",
    "y_full = data_train_full['label']\n",
    "\n",
    "print(f\"‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏£‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(y_full)} records ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏π‡∏ô (K-Fold CV)\")\n",
    "\n",
    "\n",
    "# --- 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Objective (‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏Ç‡∏≠‡∏á Optuna) ---\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÇ‡∏î‡∏¢ Optuna ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ \"trial\" (‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡πà‡∏ß‡∏á‡∏Ç‡∏≠‡∏á‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå\n",
    "    \n",
    "    # C (Regularization strength) - ‡∏™‡∏∏‡πà‡∏°‡πÅ‡∏ö‡∏ö log (1e-4 ‡∏ñ‡∏∂‡∏á 1e2)\n",
    "    C = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
    "    \n",
    "    # Penalty - 'saga' solver ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet'])\n",
    "    \n",
    "    # l1_ratio - ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ *‡∏ï‡πà‡∏≠‡πÄ‡∏°‡∏∑‡πà‡∏≠* penalty ‡πÄ‡∏õ‡πá‡∏ô 'elasticnet'\n",
    "    l1_ratio = None\n",
    "    if penalty == 'elasticnet':\n",
    "        l1_ratio = trial.suggest_float('l1_ratio', 0, 1)\n",
    "\n",
    "    \n",
    "    # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Pipeline ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏° Scaler ‡πÅ‡∏•‡∏∞ Model ‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô\n",
    "    pipeline_lr = Pipeline([\n",
    "        ('scaler', StandardScaler()), # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏õ‡∏£‡∏±‡∏ö‡∏™‡πÄ‡∏Å‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "        ('model', LogisticRegression(   # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
    "            C=C,\n",
    "            penalty=penalty,\n",
    "            l1_ratio=l1_ratio,\n",
    "            solver='saga',         # 'saga' ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å penalty\n",
    "            class_weight='balanced', # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ imbalance\n",
    "            random_state=42,\n",
    "            max_iter=5000,         # 'saga' ‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ iter ‡πÄ‡∏¢‡∏≠‡∏∞‡∏´‡∏ô‡πà‡∏≠‡∏¢\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # 3. ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• Pipeline ‡∏î‡πâ‡∏ß‡∏¢ Cross-validation\n",
    "    score = cross_val_score(\n",
    "        pipeline_lr, # üëà ‡πÉ‡∏ä‡πâ pipeline ‡πÅ‡∏ó‡∏ô model ‡∏ï‡∏£‡∏á‡πÜ\n",
    "        X_full, \n",
    "        y_full, \n",
    "        cv=3,                 \n",
    "        scoring='f1_weighted',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # 4. ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ F1 ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÉ‡∏´‡πâ Optuna\n",
    "    f1_avg = np.mean(score)\n",
    "    return f1_avg\n",
    "\n",
    "# --- 3. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ (Study) ---\n",
    "\n",
    "print(\"\\n‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Logistic Regression ‡∏î‡πâ‡∏ß‡∏¢ Optuna...\")\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á study object, ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ 'maximize' (‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ F1 ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î)\n",
    "pruner = optuna.pruners.MedianPruner()\n",
    "study = optuna.create_study(direction='maximize', pruner=pruner)\n",
    "\n",
    "# ‡∏™‡∏±‡πà‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ (optimize) 50 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n",
    "study.optimize(\n",
    "    objective, \n",
    "    n_trials=50, \n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# --- 4. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ---\n",
    "\n",
    "print(\"\\n--- Optuna ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ---\")\n",
    "\n",
    "print(\"‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (Best Parameters):\")\n",
    "print(study.best_params)\n",
    "print(f\"\\nF1-Weighted ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£ CV): {study.best_value:.6f}\")\n",
    "\n",
    "\n",
    "# --- 5. (‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ) ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏ö‡∏ô Test Set ---\n",
    "\n",
    "print(\"\\n‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô Pipeline ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î...\")\n",
    "\n",
    "# ‡∏î‡∏∂‡∏á‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏°‡∏≤\n",
    "best_lr_params = study.best_params\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á Pipeline ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ scaler ‡∏î‡πâ‡∏ß‡∏¢)\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression(\n",
    "        C=best_lr_params.get('C'),\n",
    "        penalty=best_lr_params.get('penalty'),\n",
    "        l1_ratio=best_lr_params.get('l1_ratio'), # ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô None ‡∏ñ‡πâ‡∏≤ penalty ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà 'elasticnet'\n",
    "        solver='saga',\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        max_iter=5000,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# ‡πÄ‡∏ó‡∏£‡∏ô Pipeline ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• \"‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\" (X_full, y_full)\n",
    "final_pipeline.fit(X_full, y_full)\n",
    "\n",
    "print(\"‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏ö‡∏ô Test Set...\")\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Test\n",
    "data_test_lr = pandas.read_csv('../data/salary.test.processed.csv').set_index('id')\n",
    "\n",
    "# ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ Pipeline (‡∏°‡∏±‡∏ô‡∏à‡∏∞ scale ‡πÅ‡∏•‡∏∞ predict ‡πÉ‡∏´‡πâ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)\n",
    "data_test_lr['prediction'] = final_pipeline.predict(data_test_lr.drop(['label'], axis='columns'))\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ö‡∏ô Test Set\n",
    "print(\"\\nLogistic Regression (Optuna-Tuned) Confusion Matrix:\")\n",
    "print(sklearn.metrics.confusion_matrix(\n",
    "    y_true=data_test_lr['label'],\n",
    "    y_pred=data_test_lr['prediction']\n",
    "))\n",
    "\n",
    "report_scores_lr = sklearn.metrics.classification_report(\n",
    "    y_true=data_test_lr['label'],\n",
    "    y_pred=data_test_lr['prediction'],\n",
    "    digits=6,\n",
    "    output_dict=True\n",
    ")\n",
    "df_score_lr = pandas.DataFrame(report_scores_lr).transpose()\n",
    "print(\"\\nLogistic Regression (Optuna-Tuned) Report:\")\n",
    "print(df_score_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "58204a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'C': 3.5518274294091126, \n",
    "    'penalty': 'l2', \n",
    "    # 'l1_ratio': 0.349891944349909\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c40209",
   "metadata": {},
   "source": [
    "### Class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4e449d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Testing LogReg with Class Weight ---\n",
      "Model training complete.\n",
      "\n",
      "LogReg (Tuned + Class Weight) Report:\n",
      "              precision    recall  f1-score      support\n",
      "0.0            0.873703  0.801738  0.836175  2416.000000\n",
      "1.0            0.755986  0.841270  0.796351  1764.000000\n",
      "accuracy       0.818421  0.818421  0.818421     0.818421\n",
      "macro avg      0.814844  0.821504  0.816263  4180.000000\n",
      "weighted avg   0.824025  0.818421  0.819369  4180.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "print(\"--- 1. Testing LogReg with Class Weight ---\")\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    data_train_full = pandas.read_csv('../data/salary.train.processed.csv').set_index('id')\n",
    "    data_test_lr = pandas.read_csv('../data/salary.test.processed.csv').set_index('id')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå salary.train.processed.csv ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path\")\n",
    "    # exit() \n",
    "\n",
    "X_full = data_train_full.drop(['label'], axis='columns')\n",
    "y_full = data_train_full['label']\n",
    "X_test = data_test_lr.drop(['label'], axis='columns')\n",
    "y_test = data_test_lr['label']\n",
    "\n",
    "# --- Define Parameters ---\n",
    "best_lr_params = best_params\n",
    "# --- Create and Train Pipeline ---\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), # Step 1: Scale\n",
    "    ('model', LogisticRegression(\n",
    "        **best_lr_params,\n",
    "        class_weight='balanced', # üëà Add weight\n",
    "        solver='saga',\n",
    "        max_iter=5000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_full, y_full) # Train on original data\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# --- Evaluate ---\n",
    "y_pred = pipeline.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, digits=6, output_dict=True)\n",
    "df_report = pandas.DataFrame(report).transpose()\n",
    "\n",
    "print(\"\\nLogReg (Tuned + Class Weight) Report:\")\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fc4476",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "12d14bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. Testing LogReg with SMOTE ---\n",
      "Applying SMOTE...\n",
      "New resampled label distribution:\n",
      "label\n",
      "1.0    9719\n",
      "0.0    9719\n",
      "Name: count, dtype: int64\n",
      "Model training complete.\n",
      "\n",
      "LogReg (Tuned + SMOTE) Report:\n",
      "              precision    recall  f1-score      support\n",
      "0.0            0.874322  0.800497  0.835782  2416.000000\n",
      "1.0            0.755081  0.842404  0.796356  1764.000000\n",
      "accuracy       0.818182  0.818182  0.818182     0.818182\n",
      "macro avg      0.814702  0.821450  0.816069  4180.000000\n",
      "weighted avg   0.824001  0.818182  0.819144  4180.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(\"\\n--- 2. Testing LogReg with SMOTE ---\")\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    data_train_full = pandas.read_csv('../data/salary.train.processed.csv').set_index('id')\n",
    "    data_test_lr = pandas.read_csv('../data/salary.test.processed.csv').set_index('id')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå salary.train.processed.csv ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path\")\n",
    "    # exit() \n",
    "\n",
    "X_full = data_train_full.drop(['label'], axis='columns')\n",
    "y_full = data_train_full['label']\n",
    "X_test = data_test_lr.drop(['label'], axis='columns')\n",
    "y_test = data_test_lr['label']\n",
    "\n",
    "# --- Apply SMOTE ---\n",
    "print(\"Applying SMOTE...\")\n",
    "smote = SMOTE(random_state=42, n_jobs=-1)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_full, y_full)\n",
    "print(f\"New resampled label distribution:\\n{y_resampled.value_counts()}\")\n",
    "\n",
    "# --- Define Parameters ---\n",
    "best_lr_params = best_params\n",
    "\n",
    "# --- Create and Train Pipeline ---\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), # Step 1: Scale\n",
    "    ('model', LogisticRegression(\n",
    "        **best_lr_params,\n",
    "        # ‚ö†Ô∏è NO 'class_weight'\n",
    "        solver='saga',\n",
    "        max_iter=5000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_resampled, y_resampled) # Train on SMOTEd data\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# --- Evaluate ---\n",
    "y_pred = pipeline.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, digits=6, output_dict=True)\n",
    "df_report = pandas.DataFrame(report).transpose()\n",
    "\n",
    "print(\"\\nLogReg (Tuned + SMOTE) Report:\")\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa13b70",
   "metadata": {},
   "source": [
    "### SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "465dfea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. Testing LogReg with SMOTETomek ---\n",
      "Applying SMOTETomek...\n",
      "New resampled label distribution:\n",
      "label\n",
      "1.0    8914\n",
      "0.0    8914\n",
      "Name: count, dtype: int64\n",
      "Model training complete.\n",
      "\n",
      "LogReg (Tuned + SMOTETomek) Report:\n",
      "              precision    recall  f1-score      support\n",
      "0.0            0.881084  0.794288  0.835438  2416.000000\n",
      "1.0            0.751748  0.853175  0.799257  1764.000000\n",
      "accuracy       0.819139  0.819139  0.819139     0.819139\n",
      "macro avg      0.816416  0.823731  0.817347  4180.000000\n",
      "weighted avg   0.826503  0.819139  0.820169  4180.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "print(\"\\n--- 3. Testing LogReg with SMOTETomek ---\")\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    data_train_full = pandas.read_csv('../data/salary.train.processed.csv').set_index('id')\n",
    "    data_test_lr = pandas.read_csv('../data/salary.test.processed.csv').set_index('id')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå salary.train.processed.csv ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path\")\n",
    "    # exit() \n",
    "\n",
    "X_full = data_train_full.drop(['label'], axis='columns')\n",
    "y_full = data_train_full['label']\n",
    "X_test = data_test_lr.drop(['label'], axis='columns')\n",
    "y_test = data_test_lr['label']\n",
    "\n",
    "# --- Apply SMOTETomek ---\n",
    "print(\"Applying SMOTETomek...\")\n",
    "smt = SMOTETomek(random_state=42, n_jobs=-1)\n",
    "X_resampled, y_resampled = smt.fit_resample(X_full, y_full)\n",
    "print(f\"New resampled label distribution:\\n{y_resampled.value_counts()}\")\n",
    "\n",
    "# --- Define Parameters ---\n",
    "best_lr_params = best_params\n",
    "\n",
    "# --- Create and Train Pipeline ---\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), # Step 1: Scale\n",
    "    ('model', LogisticRegression(\n",
    "        **best_lr_params,\n",
    "        # ‚ö†Ô∏è NO 'class_weight'\n",
    "        solver='saga',\n",
    "        max_iter=5000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_resampled, y_resampled) # Train on SMOTETomek data\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# --- Evaluate ---\n",
    "y_pred = pipeline.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, digits=6, output_dict=True)\n",
    "df_report = pandas.DataFrame(report).transpose()\n",
    "\n",
    "print(\"\\nLogReg (Tuned + SMOTETomek) Report:\")\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846f4864",
   "metadata": {},
   "source": [
    "### ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0df67c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4. Testing LogReg with ADASYN ---\n",
      "Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå salary.train.processed.csv ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path\n",
      "Applying ADASYN...\n",
      "New resampled label distribution:\n",
      "label\n",
      "1.0    9726\n",
      "0.0    9719\n",
      "Name: count, dtype: int64\n",
      "Model training complete.\n",
      "\n",
      "LogReg (Tuned + ADASYN) Report:\n",
      "              precision    recall  f1-score      support\n",
      "0.0            0.892278  0.774834  0.829420  2416.000000\n",
      "1.0            0.738713  0.871882  0.799792  1764.000000\n",
      "accuracy       0.815789  0.815789  0.815789     0.815789\n",
      "macro avg      0.815496  0.823358  0.814606  4180.000000\n",
      "weighted avg   0.827472  0.815789  0.816916  4180.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "print(\"\\n--- 4. Testing LogReg with ADASYN ---\")\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    data_train_full = pandas.read_csv('./data/salary.train.processed.csv').set_index('id')\n",
    "    data_test_lr = pandas.read_csv('./data/salary.test.processed.csv').set_index('id')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå salary.train.processed.csv ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path\")\n",
    "    # exit() \n",
    "\n",
    "X_full = data_train_full.drop(['label'], axis='columns')\n",
    "y_full = data_train_full['label']\n",
    "X_test = data_test_lr.drop(['label'], axis='columns')\n",
    "y_test = data_test_lr['label']\n",
    "\n",
    "# --- Apply ADASYN ---\n",
    "print(\"Applying ADASYN...\")\n",
    "ada = ADASYN(random_state=42, n_jobs=-1)\n",
    "X_resampled, y_resampled = ada.fit_resample(X_full, y_full)\n",
    "print(f\"New resampled label distribution:\\n{y_resampled.value_counts()}\")\n",
    "\n",
    "# --- Define Parameters ---\n",
    "best_lr_params = best_params\n",
    "\n",
    "# --- Create and Train Pipeline ---\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), # Step 1: Scale\n",
    "    ('model', LogisticRegression(\n",
    "        **best_lr_params,\n",
    "        # ‚ö†Ô∏è NO 'class_weight'\n",
    "        solver='saga',\n",
    "        max_iter=5000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_resampled, y_resampled) # Train on ADASYN data\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# --- Evaluate ---\n",
    "y_pred = pipeline.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, digits=6, output_dict=True)\n",
    "df_report = pandas.DataFrame(report).transpose()\n",
    "\n",
    "print(\"\\nLogReg (Tuned + ADASYN) Report:\")\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f480b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
