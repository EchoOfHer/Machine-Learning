{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "737ed0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (16720, 56)\n",
      "Testing features shape: (4180, 56)\n",
      "\n",
      "Training the model...\n",
      "Model training complete!\n",
      "\n",
      "Model Accuracy on Test Data: 82.11%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8432    0.8481    0.8456      2416\n",
      "         1.0     0.7903    0.7840    0.7871      1764\n",
      "\n",
      "    accuracy                         0.8211      4180\n",
      "   macro avg     0.8167    0.8161    0.8164      4180\n",
      "weighted avg     0.8209    0.8211    0.8210      4180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# --- Step 1: Load Your PROCESSED Data ---\n",
    "# We use the clean CSVs you just saved\n",
    "try:\n",
    "    train_df = pd.read_csv('../data/salary.train.processed.csv', index_col='id')\n",
    "    test_df = pd.read_csv('../data/salary.test.processed.csv', index_col='id')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Could not find the processed CSV files.\")\n",
    "    print(\"Please make sure 'salary.train.processed.csv' and 'salary.test.processed.csv' are in the './data/' folder.\")\n",
    "    # Stop here if files aren't found\n",
    "    raise\n",
    "    \n",
    "\n",
    "# --- Step 2: Separate Features (X) and Target (y) ---\n",
    "# The 'label' column is our target (y)\n",
    "# All other columns are our features (X)\n",
    "\n",
    "# Training data\n",
    "X_train = train_df.drop('label', axis=1)\n",
    "y_train = train_df['label']\n",
    "\n",
    "# Test data\n",
    "X_test = test_df.drop('label', axis=1)\n",
    "y_test = test_df['label']\n",
    "\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Testing features shape: {X_test.shape}\")\n",
    "\n",
    "\n",
    "# --- Step 3: Initialize and Train the Model ---\n",
    "# We add max_iter=1000 to help the model solve for the best fit\n",
    "# 'random_state=42' just ensures you get the same result as me\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "print(\"\\nTraining the model...\")\n",
    "log_reg.fit(X_train, y_train)\n",
    "print(\"Model training complete!\")\n",
    "\n",
    "\n",
    "# --- Step 4: Evaluate the Model ---\n",
    "# Make predictions on the (unseen) test data\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Check the accuracy\n",
    "# This tells us what percentage of predictions were correct\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy on Test Data: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Get a detailed report (precision, recall, f1-score)\n",
    "# This is much more useful than just accuracy\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fd41829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 07:00:50,735] A new study created in memory with name: no-name-42188d89-0f6e-4a93-8e40-bc2db57dac50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏£‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î 16720 records ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏π‡∏ô (K-Fold CV)\n",
      "\n",
      "‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Logistic Regression ‡∏î‡πâ‡∏ß‡∏¢ Optuna...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fae669085334e1ba8964b4a9a104e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 07:00:54,165] Trial 0 finished with value: 0.4273580268070503 and parameters: {'C': 0.00014333704798952278, 'penalty': 'elasticnet', 'l1_ratio': 0.7652225025342507}. Best is trial 0 with value: 0.4273580268070503.\n",
      "[I 2025-10-22 07:01:01,784] Trial 1 finished with value: 0.8125680134395764 and parameters: {'C': 14.522194869951448, 'penalty': 'l1'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:01:08,390] Trial 2 finished with value: 0.8125680134395764 and parameters: {'C': 11.708657930091368, 'penalty': 'elasticnet', 'l1_ratio': 0.4529649291521767}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:01:13,881] Trial 3 finished with value: 0.8125680134395764 and parameters: {'C': 36.34301570037935, 'penalty': 'l1'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:01:14,342] Trial 4 finished with value: 0.8051782639387195 and parameters: {'C': 0.001298501656926325, 'penalty': 'l2'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:01:19,649] Trial 5 finished with value: 0.8125680134395764 and parameters: {'C': 8.20941912379616, 'penalty': 'l1'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:01:23,871] Trial 6 finished with value: 0.8125680134395764 and parameters: {'C': 32.851170989474774, 'penalty': 'l2'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:01:31,872] Trial 7 finished with value: 0.811690792270897 and parameters: {'C': 0.06260008906691687, 'penalty': 'elasticnet', 'l1_ratio': 0.5485900658934848}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:01:42,825] Trial 8 finished with value: 0.8118667172612707 and parameters: {'C': 0.11066454533455773, 'penalty': 'elasticnet', 'l1_ratio': 0.5885737042952189}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:01:43,209] Trial 9 finished with value: 0.7410186790478286 and parameters: {'C': 0.0004443969162760025, 'penalty': 'l1'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:01:55,253] Trial 10 finished with value: 0.8123966335037319 and parameters: {'C': 0.25202440209612764, 'penalty': 'l1'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:02:00,531] Trial 11 finished with value: 0.8125680134395764 and parameters: {'C': 1.6203874834286704, 'penalty': 'elasticnet', 'l1_ratio': 0.04041381547458295}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:02:18,863] Trial 12 finished with value: 0.812567948262711 and parameters: {'C': 1.413085695694075, 'penalty': 'l1'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:02:24,096] Trial 13 finished with value: 0.8125680134395764 and parameters: {'C': 96.33599447656208, 'penalty': 'elasticnet', 'l1_ratio': 0.18479044571820874}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:02:25,158] Trial 14 finished with value: 0.8105329250929891 and parameters: {'C': 0.008430822360302266, 'penalty': 'l2'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:02:31,508] Trial 15 finished with value: 0.8124502879730509 and parameters: {'C': 3.379270773627032, 'penalty': 'l1'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:02:36,942] Trial 16 finished with value: 0.8125680134395764 and parameters: {'C': 10.52380992047487, 'penalty': 'elasticnet', 'l1_ratio': 0.9447162877840118}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:02:47,610] Trial 17 finished with value: 0.8123325935364453 and parameters: {'C': 0.3291145596535806, 'penalty': 'elasticnet', 'l1_ratio': 0.3065127720517585}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:02:50,283] Trial 18 finished with value: 0.8116216900021164 and parameters: {'C': 0.019113583312237125, 'penalty': 'l1'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:02:54,497] Trial 19 finished with value: 0.8125067591152803 and parameters: {'C': 0.6029802322938642, 'penalty': 'l2'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:02:59,877] Trial 20 finished with value: 0.8125680134395764 and parameters: {'C': 10.346136367392631, 'penalty': 'elasticnet', 'l1_ratio': 0.3858726355120712}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:03:05,384] Trial 21 finished with value: 0.8125680134395764 and parameters: {'C': 73.85069585296388, 'penalty': 'l1'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:03:10,705] Trial 22 finished with value: 0.8125680134395764 and parameters: {'C': 31.262967080320234, 'penalty': 'l1'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:03:16,564] Trial 23 finished with value: 0.8125090952417461 and parameters: {'C': 4.31961592014106, 'penalty': 'l1'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:03:21,938] Trial 24 finished with value: 0.8125680134395764 and parameters: {'C': 22.005233987916064, 'penalty': 'l1'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:03:40,062] Trial 25 finished with value: 0.812567948262711 and parameters: {'C': 1.3943868769897758, 'penalty': 'l1'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:03:45,591] Trial 26 finished with value: 0.8125680134395764 and parameters: {'C': 24.933089836182457, 'penalty': 'l1'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:03:50,914] Trial 27 finished with value: 0.8125680134395764 and parameters: {'C': 89.43180399527525, 'penalty': 'l1'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:03:55,109] Trial 28 finished with value: 0.8125680134395764 and parameters: {'C': 4.0140337656788505, 'penalty': 'l2'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:04:00,449] Trial 29 finished with value: 0.8125680134395764 and parameters: {'C': 12.073727412311309, 'penalty': 'elasticnet', 'l1_ratio': 0.6933577510870937}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:04:13,738] Trial 30 finished with value: 0.8124510645564902 and parameters: {'C': 0.791617827143295, 'penalty': 'elasticnet', 'l1_ratio': 0.9934915067371625}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:04:19,185] Trial 31 finished with value: 0.8125680134395764 and parameters: {'C': 5.908793358420997, 'penalty': 'l1'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:04:24,179] Trial 32 finished with value: 0.8125680134395764 and parameters: {'C': 46.47198276427648, 'penalty': 'l1'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:04:29,462] Trial 33 finished with value: 0.8125680134395764 and parameters: {'C': 13.402836181760211, 'penalty': 'l1'}. Best is trial 1 with value: 0.8125680134395764.\n",
      "[I 2025-10-22 07:04:53,779] Trial 34 finished with value: 0.8126280693641567 and parameters: {'C': 2.57630962702035, 'penalty': 'l1'}. Best is trial 34 with value: 0.8126280693641567.\n",
      "[I 2025-10-22 07:04:57,862] Trial 35 finished with value: 0.8125680134395764 and parameters: {'C': 1.770292352157537, 'penalty': 'l2'}. Best is trial 34 with value: 0.8126280693641567.\n",
      "[I 2025-10-22 07:05:03,161] Trial 36 finished with value: 0.8125680134395764 and parameters: {'C': 20.874373868031142, 'penalty': 'l1'}. Best is trial 34 with value: 0.8126280693641567.\n",
      "[I 2025-10-22 07:05:26,980] Trial 37 finished with value: 0.8126280693641567 and parameters: {'C': 2.546912665709214, 'penalty': 'l1'}. Best is trial 34 with value: 0.8126280693641567.\n",
      "[I 2025-10-22 07:05:32,908] Trial 38 finished with value: 0.811926250635052 and parameters: {'C': 0.12553988859040993, 'penalty': 'l1'}. Best is trial 34 with value: 0.8126280693641567.\n",
      "[I 2025-10-22 07:05:39,165] Trial 39 finished with value: 0.8112828520096849 and parameters: {'C': 0.03361086284757719, 'penalty': 'elasticnet', 'l1_ratio': 0.3874360609823997}. Best is trial 34 with value: 0.8126280693641567.\n",
      "[I 2025-10-22 07:05:40,365] Trial 40 finished with value: 0.8072078180661962 and parameters: {'C': 0.004464881630956165, 'penalty': 'l1'}. Best is trial 34 with value: 0.8126280693641567.\n",
      "[I 2025-10-22 07:06:06,765] Trial 41 finished with value: 0.8125090952417461 and parameters: {'C': 2.7963421741633105, 'penalty': 'l1'}. Best is trial 34 with value: 0.8126280693641567.\n",
      "[I 2025-10-22 07:06:12,128] Trial 42 finished with value: 0.8125680134395764 and parameters: {'C': 6.623329836991077, 'penalty': 'l1'}. Best is trial 34 with value: 0.8126280693641567.\n",
      "[I 2025-10-22 07:06:17,379] Trial 43 finished with value: 0.8125680134395764 and parameters: {'C': 45.78029415764161, 'penalty': 'l1'}. Best is trial 34 with value: 0.8126280693641567.\n",
      "[I 2025-10-22 07:06:39,033] Trial 44 finished with value: 0.8123944880627331 and parameters: {'C': 0.6137215424310106, 'penalty': 'l1'}. Best is trial 34 with value: 0.8126280693641567.\n",
      "[I 2025-10-22 07:06:44,251] Trial 45 finished with value: 0.8125680134395764 and parameters: {'C': 2.605906729592088, 'penalty': 'elasticnet', 'l1_ratio': 0.003331319523345977}. Best is trial 34 with value: 0.8126280693641567.\n",
      "[I 2025-10-22 07:06:48,408] Trial 46 finished with value: 0.8125680134395764 and parameters: {'C': 17.2174671358884, 'penalty': 'l2'}. Best is trial 34 with value: 0.8126280693641567.\n",
      "[I 2025-10-22 07:06:53,400] Trial 47 finished with value: 0.8125680134395764 and parameters: {'C': 45.034343860349416, 'penalty': 'l1'}. Best is trial 34 with value: 0.8126280693641567.\n",
      "[I 2025-10-22 07:06:53,725] Trial 48 finished with value: 0.7540657457859249 and parameters: {'C': 0.0001511723043085457, 'penalty': 'elasticnet', 'l1_ratio': 0.20730743182734457}. Best is trial 34 with value: 0.8126280693641567.\n",
      "[I 2025-10-22 07:07:05,240] Trial 49 finished with value: 0.8123966335037319 and parameters: {'C': 0.2572595892278327, 'penalty': 'l1'}. Best is trial 34 with value: 0.8126280693641567.\n",
      "\n",
      "--- Optuna ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ---\n",
      "‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (Best Parameters):\n",
      "{'C': 2.57630962702035, 'penalty': 'l1'}\n",
      "\n",
      "F1-Weighted ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£ CV): 0.812628\n",
      "\n",
      "‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô Pipeline ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î...\n",
      "‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏ö‡∏ô Test Set...\n",
      "\n",
      "Logistic Regression (Optuna-Tuned) Confusion Matrix:\n",
      "[[1934  482]\n",
      " [ 268 1496]]\n",
      "\n",
      "Logistic Regression (Optuna-Tuned) Report:\n",
      "              precision    recall  f1-score      support\n",
      "0.0            0.878292  0.800497  0.837592  2416.000000\n",
      "1.0            0.756320  0.848073  0.799572  1764.000000\n",
      "accuracy       0.820574  0.820574  0.820574     0.820574\n",
      "macro avg      0.817306  0.824285  0.818582  4180.000000\n",
      "weighted avg   0.826819  0.820574  0.821547  4180.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import optuna\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline # üëà ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# --- 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ---\n",
    "try:\n",
    "    data_train_full = pandas.read_csv('../data/salary.train.processed.csv').set_index('id')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå salary.train.processed.csv ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path\")\n",
    "    # exit() \n",
    "\n",
    "X_full = data_train_full.drop(['label'], axis='columns')\n",
    "y_full = data_train_full['label']\n",
    "\n",
    "print(f\"‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏£‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(y_full)} records ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏π‡∏ô (K-Fold CV)\")\n",
    "\n",
    "\n",
    "# --- 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Objective (‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏Ç‡∏≠‡∏á Optuna) ---\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÇ‡∏î‡∏¢ Optuna ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ \"trial\" (‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡πà‡∏ß‡∏á‡∏Ç‡∏≠‡∏á‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå\n",
    "    \n",
    "    # C (Regularization strength) - ‡∏™‡∏∏‡πà‡∏°‡πÅ‡∏ö‡∏ö log (1e-4 ‡∏ñ‡∏∂‡∏á 1e2)\n",
    "    C = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
    "    \n",
    "    # Penalty - 'saga' solver ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet'])\n",
    "    \n",
    "    # l1_ratio - ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ *‡∏ï‡πà‡∏≠‡πÄ‡∏°‡∏∑‡πà‡∏≠* penalty ‡πÄ‡∏õ‡πá‡∏ô 'elasticnet'\n",
    "    l1_ratio = None\n",
    "    if penalty == 'elasticnet':\n",
    "        l1_ratio = trial.suggest_float('l1_ratio', 0, 1)\n",
    "\n",
    "    \n",
    "    # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Pipeline ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏° Scaler ‡πÅ‡∏•‡∏∞ Model ‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô\n",
    "    pipeline_lr = Pipeline([\n",
    "        ('scaler', StandardScaler()), # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏õ‡∏£‡∏±‡∏ö‡∏™‡πÄ‡∏Å‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "        ('model', LogisticRegression(   # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
    "            C=C,\n",
    "            penalty=penalty,\n",
    "            l1_ratio=l1_ratio,\n",
    "            solver='saga',         # 'saga' ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å penalty\n",
    "            class_weight='balanced', # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ imbalance\n",
    "            random_state=42,\n",
    "            max_iter=5000,         # 'saga' ‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ iter ‡πÄ‡∏¢‡∏≠‡∏∞‡∏´‡∏ô‡πà‡∏≠‡∏¢\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # 3. ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• Pipeline ‡∏î‡πâ‡∏ß‡∏¢ Cross-validation\n",
    "    score = cross_val_score(\n",
    "        pipeline_lr, # üëà ‡πÉ‡∏ä‡πâ pipeline ‡πÅ‡∏ó‡∏ô model ‡∏ï‡∏£‡∏á‡πÜ\n",
    "        X_full, \n",
    "        y_full, \n",
    "        cv=3,                 \n",
    "        scoring='f1_weighted',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # 4. ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ F1 ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÉ‡∏´‡πâ Optuna\n",
    "    f1_avg = np.mean(score)\n",
    "    return f1_avg\n",
    "\n",
    "# --- 3. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ (Study) ---\n",
    "\n",
    "print(\"\\n‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Logistic Regression ‡∏î‡πâ‡∏ß‡∏¢ Optuna...\")\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á study object, ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ 'maximize' (‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ F1 ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î)\n",
    "pruner = optuna.pruners.MedianPruner()\n",
    "study = optuna.create_study(direction='maximize', pruner=pruner)\n",
    "\n",
    "# ‡∏™‡∏±‡πà‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ (optimize) 50 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n",
    "study.optimize(\n",
    "    objective, \n",
    "    n_trials=50, \n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# --- 4. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ---\n",
    "\n",
    "print(\"\\n--- Optuna ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ---\")\n",
    "\n",
    "print(\"‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (Best Parameters):\")\n",
    "print(study.best_params)\n",
    "print(f\"\\nF1-Weighted ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£ CV): {study.best_value:.6f}\")\n",
    "\n",
    "\n",
    "# --- 5. (‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ) ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏ö‡∏ô Test Set ---\n",
    "\n",
    "print(\"\\n‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô Pipeline ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î...\")\n",
    "\n",
    "# ‡∏î‡∏∂‡∏á‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏°‡∏≤\n",
    "best_lr_params = study.best_params\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á Pipeline ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ scaler ‡∏î‡πâ‡∏ß‡∏¢)\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression(\n",
    "        C=best_lr_params.get('C'),\n",
    "        penalty=best_lr_params.get('penalty'),\n",
    "        l1_ratio=best_lr_params.get('l1_ratio'), # ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô None ‡∏ñ‡πâ‡∏≤ penalty ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà 'elasticnet'\n",
    "        solver='saga',\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        max_iter=5000,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# ‡πÄ‡∏ó‡∏£‡∏ô Pipeline ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• \"‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\" (X_full, y_full)\n",
    "final_pipeline.fit(X_full, y_full)\n",
    "\n",
    "print(\"‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏ö‡∏ô Test Set...\")\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Test\n",
    "data_test_lr = pandas.read_csv('../data/salary.test.processed.csv').set_index('id')\n",
    "\n",
    "# ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ Pipeline (‡∏°‡∏±‡∏ô‡∏à‡∏∞ scale ‡πÅ‡∏•‡∏∞ predict ‡πÉ‡∏´‡πâ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)\n",
    "data_test_lr['prediction'] = final_pipeline.predict(data_test_lr.drop(['label'], axis='columns'))\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ö‡∏ô Test Set\n",
    "print(\"\\nLogistic Regression (Optuna-Tuned) Confusion Matrix:\")\n",
    "print(sklearn.metrics.confusion_matrix(\n",
    "    y_true=data_test_lr['label'],\n",
    "    y_pred=data_test_lr['prediction']\n",
    "))\n",
    "\n",
    "report_scores_lr = sklearn.metrics.classification_report(\n",
    "    y_true=data_test_lr['label'],\n",
    "    y_pred=data_test_lr['prediction'],\n",
    "    digits=6,\n",
    "    output_dict=True\n",
    ")\n",
    "df_score_lr = pandas.DataFrame(report_scores_lr).transpose()\n",
    "print(\"\\nLogistic Regression (Optuna-Tuned) Report:\")\n",
    "print(df_score_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58204a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = best_lr_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c40209",
   "metadata": {},
   "source": [
    "### Class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e449d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Testing LogReg with Class Weight ---\n",
      "Model training complete.\n",
      "\n",
      "LogReg (Tuned + Class Weight) Report:\n",
      "              precision    recall  f1-score      support\n",
      "0.0            0.878292  0.800497  0.837592  2416.000000\n",
      "1.0            0.756320  0.848073  0.799572  1764.000000\n",
      "accuracy       0.820574  0.820574  0.820574     0.820574\n",
      "macro avg      0.817306  0.824285  0.818582  4180.000000\n",
      "weighted avg   0.826819  0.820574  0.821547  4180.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "print(\"--- 1. Testing LogReg with Class Weight ---\")\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    data_train_full = pandas.read_csv('../data/salary.train.processed.csv').set_index('id')\n",
    "    data_test_lr = pandas.read_csv('../data/salary.test.processed.csv').set_index('id')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå salary.train.processed.csv ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path\")\n",
    "    # exit() \n",
    "\n",
    "X_full = data_train_full.drop(['label'], axis='columns')\n",
    "y_full = data_train_full['label']\n",
    "X_test = data_test_lr.drop(['label'], axis='columns')\n",
    "y_test = data_test_lr['label']\n",
    "\n",
    "# --- Define Parameters ---\n",
    "best_lr_params = best_params\n",
    "# --- Create and Train Pipeline ---\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), # Step 1: Scale\n",
    "    ('model', LogisticRegression(\n",
    "        **best_lr_params,\n",
    "        class_weight='balanced', # üëà Add weight\n",
    "        solver='saga',\n",
    "        max_iter=5000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_full, y_full) # Train on original data\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# --- Evaluate ---\n",
    "y_pred = pipeline.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, digits=6, output_dict=True)\n",
    "df_report = pandas.DataFrame(report).transpose()\n",
    "\n",
    "print(\"\\nLogReg (Tuned + Class Weight) Report:\")\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fc4476",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12d14bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. Testing LogReg with SMOTE ---\n",
      "Applying SMOTE...\n",
      "New resampled label distribution:\n",
      "label\n",
      "1.0    9719\n",
      "0.0    9719\n",
      "Name: count, dtype: int64\n",
      "Model training complete.\n",
      "\n",
      "LogReg (Tuned + SMOTE) Report:\n",
      "              precision    recall  f1-score      support\n",
      "0.0            0.878126  0.799255  0.836836  2416.000000\n",
      "1.0            0.755174  0.848073  0.798932  1764.000000\n",
      "accuracy       0.819856  0.819856  0.819856     0.819856\n",
      "macro avg      0.816650  0.823664  0.817884  4180.000000\n",
      "weighted avg   0.826239  0.819856  0.820840  4180.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(\"\\n--- 2. Testing LogReg with SMOTE ---\")\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    data_train_full = pandas.read_csv('../data/salary.train.processed.csv').set_index('id')\n",
    "    data_test_lr = pandas.read_csv('../data/salary.test.processed.csv').set_index('id')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå salary.train.processed.csv ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path\")\n",
    "    # exit() \n",
    "\n",
    "X_full = data_train_full.drop(['label'], axis='columns')\n",
    "y_full = data_train_full['label']\n",
    "X_test = data_test_lr.drop(['label'], axis='columns')\n",
    "y_test = data_test_lr['label']\n",
    "\n",
    "# --- Apply SMOTE ---\n",
    "print(\"Applying SMOTE...\")\n",
    "smote = SMOTE(random_state=42, n_jobs=-1)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_full, y_full)\n",
    "print(f\"New resampled label distribution:\\n{y_resampled.value_counts()}\")\n",
    "\n",
    "# --- Define Parameters ---\n",
    "best_lr_params = best_params\n",
    "\n",
    "# --- Create and Train Pipeline ---\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), # Step 1: Scale\n",
    "    ('model', LogisticRegression(\n",
    "        **best_lr_params,\n",
    "        # ‚ö†Ô∏è NO 'class_weight'\n",
    "        solver='saga',\n",
    "        max_iter=5000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_resampled, y_resampled) # Train on SMOTEd data\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# --- Evaluate ---\n",
    "y_pred = pipeline.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, digits=6, output_dict=True)\n",
    "df_report = pandas.DataFrame(report).transpose()\n",
    "\n",
    "print(\"\\nLogReg (Tuned + SMOTE) Report:\")\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa13b70",
   "metadata": {},
   "source": [
    "### SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "465dfea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. Testing LogReg with SMOTETomek ---\n",
      "Applying SMOTETomek...\n",
      "New resampled label distribution:\n",
      "label\n",
      "1.0    9220\n",
      "0.0    9220\n",
      "Name: count, dtype: int64\n",
      "Model training complete.\n",
      "\n",
      "LogReg (Tuned + SMOTETomek) Report:\n",
      "              precision    recall  f1-score      support\n",
      "0.0            0.878304  0.797599  0.836009  2416.000000\n",
      "1.0            0.753776  0.848639  0.798400  1764.000000\n",
      "accuracy       0.819139  0.819139  0.819139     0.819139\n",
      "macro avg      0.816040  0.823119  0.817204  4180.000000\n",
      "weighted avg   0.825752  0.819139  0.820137  4180.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "print(\"\\n--- 3. Testing LogReg with SMOTETomek ---\")\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    data_train_full = pandas.read_csv('../data/salary.train.processed.csv').set_index('id')\n",
    "    data_test_lr = pandas.read_csv('../data/salary.test.processed.csv').set_index('id')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå salary.train.processed.csv ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path\")\n",
    "    # exit() \n",
    "\n",
    "X_full = data_train_full.drop(['label'], axis='columns')\n",
    "y_full = data_train_full['label']\n",
    "X_test = data_test_lr.drop(['label'], axis='columns')\n",
    "y_test = data_test_lr['label']\n",
    "\n",
    "# --- Apply SMOTETomek ---\n",
    "print(\"Applying SMOTETomek...\")\n",
    "smt = SMOTETomek(random_state=42, n_jobs=-1)\n",
    "X_resampled, y_resampled = smt.fit_resample(X_full, y_full)\n",
    "print(f\"New resampled label distribution:\\n{y_resampled.value_counts()}\")\n",
    "\n",
    "# --- Define Parameters ---\n",
    "best_lr_params = best_params\n",
    "\n",
    "# --- Create and Train Pipeline ---\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), # Step 1: Scale\n",
    "    ('model', LogisticRegression(\n",
    "        **best_lr_params,\n",
    "        # ‚ö†Ô∏è NO 'class_weight'\n",
    "        solver='saga',\n",
    "        max_iter=5000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_resampled, y_resampled) # Train on SMOTETomek data\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# --- Evaluate ---\n",
    "y_pred = pipeline.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, digits=6, output_dict=True)\n",
    "df_report = pandas.DataFrame(report).transpose()\n",
    "\n",
    "print(\"\\nLogReg (Tuned + SMOTETomek) Report:\")\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846f4864",
   "metadata": {},
   "source": [
    "### ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0df67c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4. Testing LogReg with ADASYN ---\n",
      "Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå salary.train.processed.csv ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path\n",
      "Applying ADASYN...\n",
      "New resampled label distribution:\n",
      "label\n",
      "0.0    9719\n",
      "1.0    9698\n",
      "Name: count, dtype: int64\n",
      "Model training complete.\n",
      "\n",
      "LogReg (Tuned + ADASYN) Report:\n",
      "              precision    recall  f1-score      support\n",
      "0.0            0.892344  0.771937  0.827785  2416.000000\n",
      "1.0            0.736364  0.872449  0.798651  1764.000000\n",
      "accuracy       0.814354  0.814354  0.814354     0.814354\n",
      "macro avg      0.814354  0.822193  0.813218  4180.000000\n",
      "weighted avg   0.826519  0.814354  0.815490  4180.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "print(\"\\n--- 4. Testing LogReg with ADASYN ---\")\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    data_train_full = pandas.read_csv('./data/salary.train.processed.csv').set_index('id')\n",
    "    data_test_lr = pandas.read_csv('./data/salary.test.processed.csv').set_index('id')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå salary.train.processed.csv ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path\")\n",
    "    # exit() \n",
    "\n",
    "X_full = data_train_full.drop(['label'], axis='columns')\n",
    "y_full = data_train_full['label']\n",
    "X_test = data_test_lr.drop(['label'], axis='columns')\n",
    "y_test = data_test_lr['label']\n",
    "\n",
    "# --- Apply ADASYN ---\n",
    "print(\"Applying ADASYN...\")\n",
    "ada = ADASYN(random_state=42, n_jobs=-1)\n",
    "X_resampled, y_resampled = ada.fit_resample(X_full, y_full)\n",
    "print(f\"New resampled label distribution:\\n{y_resampled.value_counts()}\")\n",
    "\n",
    "# --- Define Parameters ---\n",
    "best_lr_params = best_params\n",
    "\n",
    "# --- Create and Train Pipeline ---\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), # Step 1: Scale\n",
    "    ('model', LogisticRegression(\n",
    "        **best_lr_params,\n",
    "        # ‚ö†Ô∏è NO 'class_weight'\n",
    "        solver='saga',\n",
    "        max_iter=5000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_resampled, y_resampled) # Train on ADASYN data\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# --- Evaluate ---\n",
    "y_pred = pipeline.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, digits=6, output_dict=True)\n",
    "df_report = pandas.DataFrame(report).transpose()\n",
    "\n",
    "print(\"\\nLogReg (Tuned + ADASYN) Report:\")\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f480b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
