{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# XGBoost Model for Salary Prediction\n",
        "\n",
        "This notebook implements an XGBoost model optimized for high F1 score (>0.90) on the salary prediction dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Prepare Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load processed data\n",
        "train_data = pd.read_csv('./for_cursur/Data/salary.train.processed.csv', index_col='id')\n",
        "test_data = pd.read_csv('./for_cursur/Data/salary.test.processed.csv', index_col='id')\n",
        "live_data = pd.read_csv('./for_cursur/Data/salary.live.processed.csv', index_col='id')\n",
        "\n",
        "print(f\"Training data shape: {train_data.shape}\")\n",
        "print(f\"Test data shape: {test_data.shape}\")\n",
        "print(f\"Live data shape: {live_data.shape}\")\n",
        "\n",
        "# Check target distribution\n",
        "print(\"\\nTarget distribution in training data:\")\n",
        "print(train_data['label'].value_counts())\n",
        "print(f\"\\nClass balance: {train_data['label'].mean():.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Prepare Features and Target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features and target\n",
        "X_train = train_data.drop(columns=['label'])\n",
        "y_train = train_data['label']\n",
        "X_test = test_data.drop(columns=['label'])\n",
        "y_test = test_data['label']\n",
        "X_live = live_data\n",
        "\n",
        "print(f\"Feature matrix shape: {X_train.shape}\")\n",
        "print(f\"Features: {list(X_train.columns)}\")\n",
        "\n",
        "# Calculate class weights for imbalanced data\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
        "print(f\"\\nClass weights: {class_weight_dict}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Hyperparameter Tuning for XGBoost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Manual hyperparameter tuning (since GridSearchCV can be slow)\n",
        "def evaluate_xgb_params(params, X, y, cv_folds=5):\n",
        "    \"\"\"Evaluate XGBoost parameters using cross-validation\"\"\"\n",
        "    model = xgb.XGBClassifier(\n",
        "        **params,\n",
        "        random_state=42,\n",
        "        eval_metric='logloss',\n",
        "        early_stopping_rounds=50,\n",
        "        verbosity=0\n",
        "    )\n",
        "    \n",
        "    cv_scores = cross_val_score(\n",
        "        model, X, y, \n",
        "        cv=StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42),\n",
        "        scoring='f1',\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    \n",
        "    return cv_scores.mean(), cv_scores.std()\n",
        "\n",
        "# Test different parameter combinations\n",
        "best_score = 0\n",
        "best_params = None\n",
        "results = []\n",
        "\n",
        "# Test key parameter combinations optimized for F1 score\n",
        "test_params = [\n",
        "    {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.9, \n",
        "     'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 1.5, 'scale_pos_weight': 2},\n",
        "    {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.01, 'subsample': 0.8, \n",
        "     'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 2, 'scale_pos_weight': 3},\n",
        "    {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 1.0, \n",
        "     'colsample_bytree': 1.0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1},\n",
        "    {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.03, 'subsample': 0.85, \n",
        "     'colsample_bytree': 0.85, 'reg_alpha': 0.5, 'reg_lambda': 1.5, 'scale_pos_weight': 2.5},\n",
        "    {'n_estimators': 600, 'max_depth': 7, 'learning_rate': 0.02, 'subsample': 0.9, \n",
        "     'colsample_bytree': 0.9, 'reg_alpha': 0.2, 'reg_lambda': 1.8, 'scale_pos_weight': 2.2}\n",
        "]\n",
        "\n",
        "print(\"Testing parameter combinations...\")\n",
        "for i, params in enumerate(test_params):\n",
        "    print(f\"Testing combination {i+1}/{len(test_params)}...\")\n",
        "    mean_score, std_score = evaluate_xgb_params(params, X_train, y_train)\n",
        "    results.append((params, mean_score, std_score))\n",
        "    \n",
        "    if mean_score > best_score:\n",
        "        best_score = mean_score\n",
        "        best_params = params\n",
        "    \n",
        "    print(f\"F1 Score: {mean_score:.4f} (+/- {std_score:.4f})\")\n",
        "\n",
        "print(f\"\\nBest F1 Score: {best_score:.4f}\")\n",
        "print(f\"Best Parameters: {best_params}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train Final XGBoost Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train final model with best parameters\n",
        "final_model = xgb.XGBClassifier(\n",
        "    **best_params,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss',\n",
        "    early_stopping_rounds=50,\n",
        "    verbosity=0\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model trained successfully!\")\n",
        "print(f\"Number of features used: {final_model.n_features_in_}\")\n",
        "print(f\"Number of estimators: {final_model.n_estimators}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred_train = final_model.predict(X_train)\n",
        "y_pred_test = final_model.predict(X_test)\n",
        "y_pred_proba_test = final_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate metrics\n",
        "train_f1 = f1_score(y_train, y_pred_train)\n",
        "test_f1 = f1_score(y_test, y_pred_test)\n",
        "test_auc = roc_auc_score(y_test, y_pred_proba_test)\n",
        "\n",
        "print(\"=== MODEL PERFORMANCE ===\")\n",
        "print(f\"Training F1 Score: {train_f1:.4f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "print(f\"Test AUC Score: {test_auc:.4f}\")\n",
        "\n",
        "# Detailed classification report\n",
        "print(\"\\n=== DETAILED CLASSIFICATION REPORT ===\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=['Low Income', 'High Income'], \n",
        "            yticklabels=['Low Income', 'High Income'])\n",
        "plt.title('Confusion Matrix - XGBoost Model')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Make Predictions on Live Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on live data\n",
        "live_predictions = final_model.predict(X_live)\n",
        "live_probabilities = final_model.predict_proba(X_live)[:, 1]\n",
        "\n",
        "# Create prediction dataframe\n",
        "live_results = pd.DataFrame({\n",
        "    'id': X_live.index,\n",
        "    'predicted_label': live_predictions,\n",
        "    'probability_high_income': live_probabilities\n",
        "})\n",
        "\n",
        "print(f\"Live data predictions completed!\")\n",
        "print(f\"Number of predictions: {len(live_results)}\")\n",
        "print(f\"High income predictions: {live_predictions.sum()}\")\n",
        "print(f\"Low income predictions: {len(live_predictions) - live_predictions.sum()}\")\n",
        "\n",
        "# Show sample predictions\n",
        "print(\"\\nSample predictions:\")\n",
        "print(live_results.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Save Model and Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "joblib.dump(final_model, './for_cursur/xgb_model.joblib')\n",
        "\n",
        "# Save predictions\n",
        "live_results.to_csv('./for_cursur/xgb_predictions.csv', index=False)\n",
        "\n",
        "# Save model configuration\n",
        "model_config = {\n",
        "    'model_type': 'XGBoost',\n",
        "    'parameters': best_params,\n",
        "    'test_f1_score': test_f1,\n",
        "    'test_auc_score': test_auc,\n",
        "    'cv_mean_f1': best_score,\n",
        "    'feature_count': final_model.n_features_in_,\n",
        "    'training_samples': len(X_train),\n",
        "    'test_samples': len(X_test)\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('./for_cursur/xgb_model_config.json', 'w') as f:\n",
        "    json.dump(model_config, f, indent=2)\n",
        "\n",
        "print(\"Model and results saved successfully!\")\n",
        "print(f\"\\nFinal Test F1 Score: {test_f1:.4f}\")\n",
        "print(f\"Target achieved: {'✅ YES' if test_f1 >= 0.90 else '❌ NO'}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
