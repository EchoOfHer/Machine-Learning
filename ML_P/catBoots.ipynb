{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca5d78ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\natth\\anaconda3\\lib\\site-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in c:\\users\\natth\\anaconda3\\lib\\site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\natth\\anaconda3\\lib\\site-packages (from catboost) (3.9.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in c:\\users\\natth\\anaconda3\\lib\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\natth\\anaconda3\\lib\\site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\natth\\anaconda3\\lib\\site-packages (from catboost) (1.13.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\natth\\anaconda3\\lib\\site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in c:\\users\\natth\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\natth\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\natth\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\natth\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\natth\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\natth\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\natth\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\natth\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\natth\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\natth\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\natth\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.1.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\natth\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5534a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (16720, 89)\n",
      "Testing features shape: (4180, 89)\n",
      "\n",
      "Training the CatBoost model...\n",
      "Model training complete! Time taken: 6.41 seconds\n",
      "\n",
      "Evaluating the model on the test set...\n",
      "\n",
      "CatBoost Model Accuracy on Test Data: 82.66%\n",
      "\n",
      "CatBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8539    0.8444    0.8491      2416\n",
      "         1.0     0.7901    0.8022    0.7961      1764\n",
      "\n",
      "    accuracy                         0.8266      4180\n",
      "   macro avg     0.8220    0.8233    0.8226      4180\n",
      "weighted avg     0.8270    0.8266    0.8267      4180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time # To time the training\n",
    "\n",
    "# --- Step 1: Load Your PROCESSED Data ---\n",
    "try:\n",
    "    train_df = pd.read_csv('./Data/salary.train.processed.csv', index_col='id')\n",
    "    test_df = pd.read_csv('./Data/salary.test.processed.csv', index_col='id')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Could not find the processed CSV files.\")\n",
    "    print(\"Please make sure 'salary.train.processed.csv' and 'salary.test.processed.csv' are in the './Data/' folder.\")\n",
    "    raise\n",
    "\n",
    "# --- Step 2: Separate Features (X) and Target (y) ---\n",
    "X_train = train_df.drop('label', axis=1)\n",
    "y_train = train_df['label']\n",
    "X_test = test_df.drop('label', axis=1)\n",
    "y_test = test_df['label']\n",
    "\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Testing features shape: {X_test.shape}\")\n",
    "\n",
    "# --- Step 3: Initialize and Train the CatBoost Model ---\n",
    "# We'll use default settings first, which are often strong.\n",
    "# 'random_state=42' for reproducibility\n",
    "# 'verbose=0' suppresses training output for cleaner results\n",
    "cb_model = CatBoostClassifier(random_state=42, verbose=0)\n",
    "\n",
    "print(\"\\nTraining the CatBoost model...\")\n",
    "start_time = time.time()\n",
    "cb_model.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "print(f\"Model training complete! Time taken: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# --- Step 4: Evaluate the Model ---\n",
    "print(\"\\nEvaluating the model on the test set...\")\n",
    "y_pred_cb = cb_model.predict(X_test)\n",
    "\n",
    "# Check accuracy\n",
    "accuracy_cb = accuracy_score(y_test, y_pred_cb)\n",
    "print(f\"\\nCatBoost Model Accuracy on Test Data: {accuracy_cb * 100:.2f}%\")\n",
    "\n",
    "# Get a detailed report\n",
    "print(\"\\nCatBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_cb,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340cdc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (16720, 89)\n",
      "Testing features shape: (4180, 89)\n",
      "\n",
      "Calculated scale_pos_weight for imbalance: 1.3882\n",
      "\n",
      "Starting Optuna optimization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285cbcfda35a4c2da00908eb1dcd414d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna optimization complete! Time taken: 215.02 seconds\n",
      "\n",
      "--- Best Parameters Found by Optuna ---\n",
      "{'iterations': 963, 'depth': 9, 'learning_rate': 0.013496391303712649, 'l2_leaf_reg': 5.77926857719205, 'border_count': 72, 'random_strength': 0.12155034615711403}\n",
      "Best F1-weighted score during tuning: 0.8288\n",
      "------------------------------------------\n",
      "\n",
      "Training the FINAL CatBoost model with best params...\n",
      "Final model training complete! Time taken: 10.14 seconds\n",
      "\n",
      "Evaluating the FINAL model on the test set...\n",
      "\n",
      "Final CatBoost Model Accuracy on Test Data: 82.22%\n",
      "\n",
      "Final CatBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8811    0.8005    0.8389      2416\n",
      "         1.0     0.7572    0.8520    0.8018      1764\n",
      "\n",
      "    accuracy                         0.8222      4180\n",
      "   macro avg     0.8191    0.8263    0.8203      4180\n",
      "weighted avg     0.8288    0.8222    0.8232      4180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "import optuna\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "# Suppress Optuna's trial logging\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# --- Step 1: Load Your PROCESSED Data ---\n",
    "try:\n",
    "    train_df = pd.read_csv('./Data/salary.train.processed.csv', index_col='id')\n",
    "    test_df = pd.read_csv('./Data/salary.test.processed.csv', index_col='id')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Could not find the processed CSV files.\")\n",
    "    print(\"Please make sure 'salary.train.processed.csv' and 'salary.test.processed.csv' are in the './Data/' folder.\")\n",
    "    raise\n",
    "\n",
    "# --- Step 2: Separate Features (X) and Target (y) ---\n",
    "X_train = train_df.drop('label', axis=1)\n",
    "y_train = train_df['label']\n",
    "X_test = test_df.drop('label', axis=1)\n",
    "y_test = test_df['label']\n",
    "\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Testing features shape: {X_test.shape}\")\n",
    "\n",
    "# --- NEW: Calculate scale_pos_weight for imbalance ---\n",
    "# CatBoost uses 'scale_pos_weight' just like XGBoost\n",
    "scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "print(f\"\\nCalculated scale_pos_weight for imbalance: {scale_pos_weight:.4f}\")\n",
    "\n",
    "# --- NEW: Step 2.5: Define Optuna Objective Function ---\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    This function will be called by Optuna for each trial.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the hyperparameter search space\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-3, 10.0, log=True),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "        'random_strength': trial.suggest_float('random_strength', 1e-3, 10.0, log=True)\n",
    "    }\n",
    "    \n",
    "    # Create the CatBoost model with suggested params\n",
    "    model_cb = CatBoostClassifier(\n",
    "        **params,\n",
    "        scale_pos_weight=scale_pos_weight, # Handle imbalance\n",
    "        random_state=42,\n",
    "        verbose=0,\n",
    "        early_stopping_rounds=50 # Use early stopping for speed during tuning\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model using cross-validation (f1_weighted for imbalance)\n",
    "    # We use a simple fit/validate split here because CatBoost's early stopping\n",
    "    # is more efficient than full K-Fold CV.\n",
    "    # We'll split X_train again for this.\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "    model_cb.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], use_best_model=True)\n",
    "    \n",
    "    preds = model_cb.predict(X_val)\n",
    "    f1 = sklearn.metrics.f1_score(y_val, preds, average='weighted')\n",
    "    \n",
    "    return f1\n",
    "\n",
    "# --- NEW: Step 2.6: Run Optuna Study ---\n",
    "print(\"\\nStarting Optuna optimization...\")\n",
    "start_time_optuna = time.time()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True) # Run 50 trials\n",
    "\n",
    "end_time_optuna = time.time()\n",
    "print(f\"Optuna optimization complete! Time taken: {end_time_optuna - start_time_optuna:.2f} seconds\")\n",
    "\n",
    "# --- Store and Print the Best Parameters ---\n",
    "best_params = study.best_params\n",
    "print(\"\\n--- Best Parameters Found by Optuna ---\")\n",
    "print(best_params)\n",
    "print(f\"Best F1-weighted score during tuning: {study.best_value:.4f}\")\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "\n",
    "# --- Step 3: Initialize and Train the FINAL CatBoost Model ---\n",
    "# We use the best_params found by Optuna\n",
    "# We also add iterations (if Optuna didn't find it) and the weight\n",
    "final_params = best_params.copy()\n",
    "if 'iterations' not in final_params:\n",
    "    final_params['iterations'] = 1000 # Default high value if not tuned\n",
    "\n",
    "cb_model = CatBoostClassifier(\n",
    "    **final_params,\n",
    "    scale_pos_weight=scale_pos_weight, # Use the weight for the final model\n",
    "    random_state=42, \n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"\\nTraining the FINAL CatBoost model with best params...\")\n",
    "start_time = time.time()\n",
    "# Train on the FULL training data\n",
    "cb_model.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "print(f\"Final model training complete! Time taken: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# --- Step 4: Evaluate the FINAL Model ---\n",
    "print(\"\\nEvaluating the FINAL model on the test set...\")\n",
    "y_pred_cb = cb_model.predict(X_test)\n",
    "\n",
    "# Check accuracy\n",
    "accuracy_cb = accuracy_score(y_test, y_pred_cb)\n",
    "print(f\"\\nFinal CatBoost Model Accuracy on Test Data: {accuracy_cb * 100:.2f}%\")\n",
    "\n",
    "# Get a detailed report\n",
    "print(\"\\nFinal CatBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_cb, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc9151bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3882302528210255\n"
     ]
    }
   ],
   "source": [
    "print(scale_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56a7311a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Testing CatBoost with Class Weight ---\n",
      "Using scale_pos_weight: 1.3882\n",
      "Model training complete.\n",
      "\n",
      "CatBoost (Tuned + Class Weight) Report:\n",
      "              precision    recall  f1-score      support\n",
      "0.0            0.881093  0.800497  0.838864  2416.000000\n",
      "1.0            0.757179  0.852041  0.801814  1764.000000\n",
      "accuracy       0.822249  0.822249  0.822249     0.822249\n",
      "macro avg      0.819136  0.826269  0.820339  4180.000000\n",
      "weighted avg   0.828800  0.822249  0.823228  4180.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics\n",
    "import time\n",
    "\n",
    "print(\"--- 1. Testing CatBoost with Class Weight ---\")\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    train_df = pd.read_csv('./Data/salary.train.processed.csv', index_col='id')\n",
    "    test_df = pd.read_csv('./Data/salary.test.processed.csv', index_col='id')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Could not find the processed CSV files.\")\n",
    "    raise\n",
    "\n",
    "X_full = train_df.drop('label', axis=1)\n",
    "y_full = train_df['label']\n",
    "X_test = test_df.drop('label', axis=1)\n",
    "y_test = test_df['label']\n",
    "\n",
    "# --- Calculate Weight ---\n",
    "scale_pos_weight = len(y_full[y_full == 0]) / len(y_full[y_full == 1])\n",
    "print(f\"Using scale_pos_weight: {scale_pos_weight:.4f}\")\n",
    "\n",
    "# --- Assume 'best_params' (plural) variable exists from Optuna run ---\n",
    "# best_params = {'iterations': ..., 'depth': ..., ...}\n",
    "\n",
    "# --- Create and Train Model ---\n",
    "cb_model = CatBoostClassifier(\n",
    "    **best_params,\n",
    "    scale_pos_weight=scale_pos_weight, # ðŸ‘ˆ Add weight\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "cb_model.fit(X_full, y_full) # Train on original data\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# --- Evaluate ---\n",
    "y_pred = cb_model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, digits=6, output_dict=True)\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "print(\"\\nCatBoost (Tuned + Class Weight) Report:\")\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e95a6b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. Testing CatBoost with SMOTETomek ---\n",
      "Applying SMOTETomek...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natth\\anaconda3\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:370: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\natth\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\natth\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natth\\anaconda3\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natth\\anaconda3\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\natth\\anaconda3\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New resampled label distribution:\n",
      "label\n",
      "1.0    8914\n",
      "0.0    8914\n",
      "Name: count, dtype: int64\n",
      "Model training complete.\n",
      "\n",
      "CatBoost (Tuned + SMOTETomek) Report:\n",
      "              precision    recall  f1-score      support\n",
      "0.0            0.872558  0.813328  0.841902  2416.000000\n",
      "1.0            0.766079  0.837302  0.800108  1764.000000\n",
      "accuracy       0.823445  0.823445  0.823445     0.823445\n",
      "macro avg      0.819318  0.825315  0.821005  4180.000000\n",
      "weighted avg   0.827623  0.823445  0.824265  4180.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "print(\"\\n--- 3. Testing CatBoost with SMOTETomek ---\")\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    train_df = pd.read_csv('./Data/salary.train.processed.csv', index_col='id')\n",
    "    test_df = pd.read_csv('./Data/salary.test.processed.csv', index_col='id')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Could not find the processed CSV files.\")\n",
    "    raise\n",
    "\n",
    "X_full = train_df.drop('label', axis=1)\n",
    "y_full = train_df['label']\n",
    "X_test = test_df.drop('label', axis=1)\n",
    "y_test = test_df['label']\n",
    "\n",
    "# --- Apply SMOTETomek ---\n",
    "print(\"Applying SMOTETomek...\")\n",
    "smt = SMOTETomek(random_state=42, n_jobs=-1)\n",
    "X_resampled, y_resampled = smt.fit_resample(X_full, y_full)\n",
    "print(f\"New resampled label distribution:\\n{y_resampled.value_counts()}\")\n",
    "\n",
    "# --- Assume 'best_params' (plural) variable exists ---\n",
    "# best_params = {'iterations': ..., 'depth': ..., ...}\n",
    "\n",
    "# --- Create and Train Model ---\n",
    "cb_model = CatBoostClassifier(\n",
    "    **best_params,\n",
    "    # âš ï¸ NO 'scale_pos_weight'\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "cb_model.fit(X_resampled, y_resampled) # Train on SMOTETomek data\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# --- Evaluate ---\n",
    "y_pred = cb_model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, digits=6, output_dict=True)\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "print(\"\\nCatBoost (Tuned + SMOTETomek) Report:\")\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5e37c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
