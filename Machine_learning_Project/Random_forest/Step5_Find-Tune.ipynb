{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f2df7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import optuna\n",
    "import sklearn.metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "993a7f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\natth\\anaconda3\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\natth\\anaconda3\\lib\\site-packages (from optuna) (1.13.3)\n",
      "Requirement already satisfied: colorlog in c:\\users\\natth\\anaconda3\\lib\\site-packages (from optuna) (6.10.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\natth\\anaconda3\\lib\\site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\natth\\anaconda3\\lib\\site-packages (from optuna) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\natth\\anaconda3\\lib\\site-packages (from optuna) (2.0.34)\n",
      "Requirement already satisfied: tqdm in c:\\users\\natth\\anaconda3\\lib\\site-packages (from optuna) (4.66.5)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\natth\\anaconda3\\lib\\site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in c:\\users\\natth\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.2.3)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\natth\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\natth\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\natth\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\natth\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1307a919",
   "metadata": {},
   "source": [
    "### Find-tune using Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b7d84a",
   "metadata": {},
   "source": [
    "- Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38db1eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_full = pandas.read_csv('../data/salary.train.processed.csv').set_index('id')\n",
    "data_test_rf = pandas.read_csv('../data/salary.test.processed.csv').set_index('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a9f62d",
   "metadata": {},
   "source": [
    "- seperate the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "381251b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = data_train_full.drop(['label'], axis='columns')\n",
    "y_full = data_train_full['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbcfb27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0.0    9719\n",
       "1.0    7001\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_full['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9f16e6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9524d6b",
   "metadata": {},
   "source": [
    "### Setting optuna\n",
    "Given the imbalanced class distribution, we will utilize `class_weight` to mitigate model bias. \n",
    "\n",
    "- Base Model Configuration\n",
    "```\n",
    "`class_weight = balanced`,\n",
    "`random_state = 42` ,\n",
    "`n_jobs = -1`\n",
    "```\n",
    "- Hyper parameters\n",
    "```\n",
    "'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=50),\n",
    "'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "'min_samples_split': trial.suggest_int('min_samples_split', 2, 14),\n",
    "'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "'max_features': trial.suggest_float('max_features', 0.1, 1.0) \n",
    "```\n",
    "We'll use 3-fold cross-Validation and return the averege F1-Weight Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b55103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-07 13:43:14,088] A new study created in memory with name: no-name-855fdc4e-3b5d-402b-b6c5-d11835956f10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding parameters with Optuna...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b78ad771321437ca6137d8f5e5b3f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-07 13:43:25,858] Trial 0 finished with value: 0.760174516636997 and parameters: {'n_estimators': 250, 'max_depth': 4, 'min_samples_leaf': 9, 'min_samples_split': 5, 'criterion': 'gini', 'max_features': 0.18061571501102475}. Best is trial 0 with value: 0.760174516636997.\n",
      "[I 2025-11-07 13:43:59,546] Trial 1 finished with value: 0.8149581784005939 and parameters: {'n_estimators': 700, 'max_depth': 11, 'min_samples_leaf': 6, 'min_samples_split': 8, 'criterion': 'entropy', 'max_features': 0.5628163110642745}. Best is trial 1 with value: 0.8149581784005939.\n",
      "[I 2025-11-07 13:44:29,810] Trial 2 finished with value: 0.810737583162244 and parameters: {'n_estimators': 600, 'max_depth': 8, 'min_samples_leaf': 10, 'min_samples_split': 9, 'criterion': 'entropy', 'max_features': 0.8029647105941743}. Best is trial 1 with value: 0.8149581784005939.\n",
      "[I 2025-11-07 13:45:17,043] Trial 3 finished with value: 0.814146399512784 and parameters: {'n_estimators': 950, 'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 13, 'criterion': 'gini', 'max_features': 0.7790523107597337}. Best is trial 1 with value: 0.8149581784005939.\n",
      "[I 2025-11-07 13:45:19,925] Trial 4 finished with value: 0.7817429585801416 and parameters: {'n_estimators': 150, 'max_depth': 6, 'min_samples_leaf': 5, 'min_samples_split': 12, 'criterion': 'gini', 'max_features': 0.17364879541715783}. Best is trial 1 with value: 0.8149581784005939.\n",
      "[I 2025-11-07 13:46:23,863] Trial 5 finished with value: 0.813349762401247 and parameters: {'n_estimators': 1000, 'max_depth': 11, 'min_samples_leaf': 1, 'min_samples_split': 12, 'criterion': 'gini', 'max_features': 0.7919843114867788}. Best is trial 1 with value: 0.8149581784005939.\n",
      "[I 2025-11-07 13:46:44,195] Trial 6 finished with value: 0.8124853624962818 and parameters: {'n_estimators': 950, 'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 7, 'criterion': 'entropy', 'max_features': 0.1319500830392094}. Best is trial 1 with value: 0.8149581784005939.\n",
      "[I 2025-11-07 13:47:45,193] Trial 7 finished with value: 0.8134142009629439 and parameters: {'n_estimators': 850, 'max_depth': 12, 'min_samples_leaf': 7, 'min_samples_split': 8, 'criterion': 'gini', 'max_features': 0.9233263931099716}. Best is trial 1 with value: 0.8149581784005939.\n",
      "[I 2025-11-07 13:48:16,087] Trial 8 finished with value: 0.8030689264249883 and parameters: {'n_estimators': 900, 'max_depth': 6, 'min_samples_leaf': 8, 'min_samples_split': 12, 'criterion': 'entropy', 'max_features': 0.7128403292143358}. Best is trial 1 with value: 0.8149581784005939.\n",
      "[I 2025-11-07 13:48:40,194] Trial 9 finished with value: 0.8150670312318951 and parameters: {'n_estimators': 550, 'max_depth': 13, 'min_samples_leaf': 9, 'min_samples_split': 14, 'criterion': 'gini', 'max_features': 0.5194782426780148}. Best is trial 9 with value: 0.8150670312318951.\n",
      "[I 2025-11-07 13:48:56,573] Trial 10 finished with value: 0.8168410882913651 and parameters: {'n_estimators': 400, 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 2, 'criterion': 'gini', 'max_features': 0.39176694211435426}. Best is trial 10 with value: 0.8168410882913651.\n",
      "[I 2025-11-07 13:49:12,302] Trial 11 finished with value: 0.8168410882913651 and parameters: {'n_estimators': 400, 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 2, 'criterion': 'gini', 'max_features': 0.3774689620451668}. Best is trial 10 with value: 0.8168410882913651.\n",
      "[I 2025-11-07 13:49:30,154] Trial 12 finished with value: 0.8168410882913651 and parameters: {'n_estimators': 400, 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 2, 'criterion': 'gini', 'max_features': 0.38905813760295305}. Best is trial 10 with value: 0.8168410882913651.\n",
      "[I 2025-11-07 13:49:44,420] Trial 13 finished with value: 0.8161920403639022 and parameters: {'n_estimators': 400, 'max_depth': 14, 'min_samples_leaf': 3, 'min_samples_split': 2, 'criterion': 'gini', 'max_features': 0.3512293806525577}. Best is trial 10 with value: 0.8168410882913651.\n",
      "[I 2025-11-07 13:49:54,582] Trial 14 finished with value: 0.8170540722852392 and parameters: {'n_estimators': 350, 'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 4, 'criterion': 'gini', 'max_features': 0.34077847113467785}. Best is trial 14 with value: 0.8170540722852392.\n",
      "[I 2025-11-07 13:50:01,866] Trial 15 finished with value: 0.815509340669608 and parameters: {'n_estimators': 250, 'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 4, 'criterion': 'gini', 'max_features': 0.27089760424367315}. Best is trial 14 with value: 0.8170540722852392.\n",
      "[I 2025-11-07 13:50:21,528] Trial 16 finished with value: 0.8149136824640857 and parameters: {'n_estimators': 500, 'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 4, 'criterion': 'gini', 'max_features': 0.5137236399516246}. Best is trial 14 with value: 0.8170540722852392.\n",
      "[I 2025-11-07 13:50:26,466] Trial 17 finished with value: 0.7699487579261622 and parameters: {'n_estimators': 250, 'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 5, 'criterion': 'gini', 'max_features': 0.6233117008243698}. Best is trial 14 with value: 0.8170540722852392.\n",
      "[I 2025-11-07 13:50:48,182] Trial 18 finished with value: 0.8176777106671436 and parameters: {'n_estimators': 700, 'max_depth': 13, 'min_samples_leaf': 3, 'min_samples_split': 6, 'criterion': 'entropy', 'max_features': 0.2916329198643542}. Best is trial 18 with value: 0.8176777106671436.\n",
      "[I 2025-11-07 13:51:10,250] Trial 19 finished with value: 0.817846436550089 and parameters: {'n_estimators': 750, 'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 6, 'criterion': 'entropy', 'max_features': 0.2785855025326761}. Best is trial 19 with value: 0.817846436550089.\n",
      "[I 2025-11-07 13:51:33,538] Trial 20 finished with value: 0.817972438269682 and parameters: {'n_estimators': 800, 'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 10, 'criterion': 'entropy', 'max_features': 0.27802443984172714}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:51:55,312] Trial 21 finished with value: 0.8178080370426729 and parameters: {'n_estimators': 750, 'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 10, 'criterion': 'entropy', 'max_features': 0.2521093924133464}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:52:17,443] Trial 22 finished with value: 0.8172157463409713 and parameters: {'n_estimators': 800, 'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 10, 'criterion': 'entropy', 'max_features': 0.2386023344316164}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:52:30,016] Trial 23 finished with value: 0.799242576562278 and parameters: {'n_estimators': 750, 'max_depth': 12, 'min_samples_leaf': 2, 'min_samples_split': 10, 'criterion': 'entropy', 'max_features': 0.10270864897748214}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:52:52,900] Trial 24 finished with value: 0.8160842324602084 and parameters: {'n_estimators': 650, 'max_depth': 12, 'min_samples_leaf': 1, 'min_samples_split': 10, 'criterion': 'entropy', 'max_features': 0.43672225078693105}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:53:13,474] Trial 25 finished with value: 0.8166132821546249 and parameters: {'n_estimators': 800, 'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 9, 'criterion': 'entropy', 'max_features': 0.21607720986029436}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:53:42,985] Trial 26 finished with value: 0.8158498194742132 and parameters: {'n_estimators': 850, 'max_depth': 11, 'min_samples_leaf': 1, 'min_samples_split': 11, 'criterion': 'entropy', 'max_features': 0.4400595574215723}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:54:01,535] Trial 27 finished with value: 0.8173181412270434 and parameters: {'n_estimators': 650, 'max_depth': 14, 'min_samples_leaf': 6, 'min_samples_split': 7, 'criterion': 'entropy', 'max_features': 0.288075978914353}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:54:31,106] Trial 28 finished with value: 0.815533247781306 and parameters: {'n_estimators': 750, 'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 8, 'criterion': 'entropy', 'max_features': 0.472499716996534}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:54:40,517] Trial 29 finished with value: 0.8093190066302498 and parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 6, 'criterion': 'entropy', 'max_features': 0.17636774373354341}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:55:04,273] Trial 30 finished with value: 0.8171572861745714 and parameters: {'n_estimators': 850, 'max_depth': 12, 'min_samples_leaf': 3, 'min_samples_split': 11, 'criterion': 'entropy', 'max_features': 0.30888719101181206}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:55:21,218] Trial 31 finished with value: 0.8169180673542478 and parameters: {'n_estimators': 700, 'max_depth': 13, 'min_samples_leaf': 3, 'min_samples_split': 6, 'criterion': 'entropy', 'max_features': 0.2093822925336144}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:55:40,996] Trial 32 finished with value: 0.8173185687571978 and parameters: {'n_estimators': 700, 'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 7, 'criterion': 'entropy', 'max_features': 0.26452644947987336}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:56:09,953] Trial 33 finished with value: 0.8134470892890281 and parameters: {'n_estimators': 600, 'max_depth': 13, 'min_samples_leaf': 1, 'min_samples_split': 9, 'criterion': 'entropy', 'max_features': 0.6151604113576713}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:56:32,249] Trial 34 finished with value: 0.8174560409606325 and parameters: {'n_estimators': 800, 'max_depth': 11, 'min_samples_leaf': 3, 'min_samples_split': 6, 'criterion': 'entropy', 'max_features': 0.3178740661161119}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:56:47,182] Trial 35 finished with value: 0.81290420543448 and parameters: {'n_estimators': 750, 'max_depth': 12, 'min_samples_leaf': 5, 'min_samples_split': 9, 'criterion': 'entropy', 'max_features': 0.15680844176977418}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:56:58,170] Trial 36 finished with value: 0.8012148332183774 and parameters: {'n_estimators': 600, 'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 5, 'criterion': 'entropy', 'max_features': 0.197955898289102}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:57:13,427] Trial 37 finished with value: 0.772410717259216 and parameters: {'n_estimators': 1000, 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 11, 'criterion': 'entropy', 'max_features': 0.25135729866818646}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:58:06,681] Trial 38 finished with value: 0.812624998058802 and parameters: {'n_estimators': 700, 'max_depth': 14, 'min_samples_leaf': 6, 'min_samples_split': 8, 'criterion': 'entropy', 'max_features': 0.9928316732092215}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:58:22,386] Trial 39 finished with value: 0.7915268009438619 and parameters: {'n_estimators': 950, 'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 13, 'criterion': 'entropy', 'max_features': 0.11350159277334951}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:58:53,152] Trial 40 finished with value: 0.816147129151737 and parameters: {'n_estimators': 900, 'max_depth': 11, 'min_samples_leaf': 4, 'min_samples_split': 7, 'criterion': 'entropy', 'max_features': 0.4398943267809281}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:59:14,429] Trial 41 finished with value: 0.8171056376553155 and parameters: {'n_estimators': 800, 'max_depth': 11, 'min_samples_leaf': 3, 'min_samples_split': 6, 'criterion': 'entropy', 'max_features': 0.30975479561958563}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:59:34,831] Trial 42 finished with value: 0.8178476744602031 and parameters: {'n_estimators': 650, 'max_depth': 13, 'min_samples_leaf': 3, 'min_samples_split': 6, 'criterion': 'entropy', 'max_features': 0.32623438090367}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 13:59:58,066] Trial 43 finished with value: 0.8167765709260708 and parameters: {'n_estimators': 650, 'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 5, 'criterion': 'entropy', 'max_features': 0.377085133150338}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 14:00:12,590] Trial 44 finished with value: 0.8158679418518033 and parameters: {'n_estimators': 550, 'max_depth': 14, 'min_samples_leaf': 4, 'min_samples_split': 8, 'criterion': 'entropy', 'max_features': 0.15936902837134378}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 14:00:35,434] Trial 45 finished with value: 0.817730409341838 and parameters: {'n_estimators': 750, 'max_depth': 15, 'min_samples_leaf': 3, 'min_samples_split': 5, 'criterion': 'entropy', 'max_features': 0.23732310178075017}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 14:01:06,427] Trial 46 finished with value: 0.8169856051423581 and parameters: {'n_estimators': 900, 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 3, 'criterion': 'entropy', 'max_features': 0.23523348721183326}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 14:01:32,751] Trial 47 finished with value: 0.8173715741946104 and parameters: {'n_estimators': 750, 'max_depth': 15, 'min_samples_leaf': 5, 'min_samples_split': 3, 'criterion': 'entropy', 'max_features': 0.34587972764249897}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 14:01:47,882] Trial 48 finished with value: 0.8129623713902905 and parameters: {'n_estimators': 650, 'max_depth': 12, 'min_samples_leaf': 2, 'min_samples_split': 5, 'criterion': 'entropy', 'max_features': 0.14808430686019353}. Best is trial 20 with value: 0.817972438269682.\n",
      "[I 2025-11-07 14:02:19,824] Trial 49 finished with value: 0.807420151266052 and parameters: {'n_estimators': 850, 'max_depth': 7, 'min_samples_leaf': 8, 'min_samples_split': 7, 'criterion': 'entropy', 'max_features': 0.7350178010679751}. Best is trial 20 with value: 0.817972438269682.\n",
      "\n",
      "--- Optuna Finished! ---\n",
      "Best Parameters:\n",
      "{'n_estimators': 800, 'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 10, 'criterion': 'entropy', 'max_features': 0.27802443984172714}\n",
      "\n",
      "Best F1-Weighted (From CV): 0.817972\n"
     ]
    }
   ],
   "source": [
    "rf_class_weight = 'balanced' \n",
    "def objective(trial):    \n",
    "    param_rf = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=50),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 14),\n",
    "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "        'max_features': trial.suggest_float('max_features', 0.1, 1.0) \n",
    "    }\n",
    "    \n",
    "\n",
    "    model_rf = RandomForestClassifier(\n",
    "        **param_rf,\n",
    "        class_weight=rf_class_weight, \n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    score = cross_val_score(\n",
    "        model_rf, \n",
    "        X_full, \n",
    "        y_full, \n",
    "        cv=10,                 \n",
    "        scoring='f1_weighted',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    f1_avg = np.mean(score)\n",
    "    return f1_avg\n",
    "\n",
    "print(\"\\nFinding parameters with Optuna...\")\n",
    "\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner()\n",
    "study = optuna.create_study(direction='maximize', pruner=pruner)\n",
    "\n",
    "\n",
    "study.optimize(\n",
    "    objective, \n",
    "    n_trials=50,  \n",
    "    show_progress_bar=True \n",
    ")\n",
    "\n",
    "\n",
    "best_parameter = study.best_params \n",
    "print(\"\\n--- Optuna Finished! ---\")\n",
    "\n",
    "\n",
    "print(\"Best Parameters:\")\n",
    "print(study.best_params)\n",
    "\n",
    "print(f\"\\nBest F1-Weighted (From CV): {study.best_value:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc4a199",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ad836c",
   "metadata": {},
   "source": [
    "### Train simple model with best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd06921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_final = RandomForestClassifier(\n",
    "    **best_parameter,   \n",
    "    class_weight=rf_class_weight,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "656be7f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- prediction\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m rf_model_final\u001b[38;5;241m.\u001b[39mfit(X_full, y_full)\n\u001b[1;32m----> 2\u001b[0m data_test_rf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m rf_model_final\u001b[38;5;241m.\u001b[39mpredict(data_test_rf\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\natth\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:904\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    884\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 904\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\natth\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:946\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    944\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    945\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n\u001b[0;32m    948\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    949\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\natth\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:641\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    639\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 641\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    642\u001b[0m     X,\n\u001b[0;32m    643\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[0;32m    644\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    645\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    646\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m    647\u001b[0m )\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\natth\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    545\u001b[0m ):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\natth\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m     )\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- prediction\n"
     ]
    }
   ],
   "source": [
    "rf_model_final.fit(X_full, y_full)\n",
    "data_test_rf['prediction'] = rf_model_final.predict(data_test_rf.drop(['label'], axis='columns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815a5602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest (Optuna-Tuned) Confusion Matrix:\n",
      "[[1910  506]\n",
      " [ 232 1532]]\n",
      "\n",
      "Random Forest (Optuna-Tuned) Report:\n",
      "              precision    recall  f1-score      support\n",
      "0.0            0.891690  0.790563  0.838087  2416.000000\n",
      "1.0            0.751717  0.868481  0.805892  1764.000000\n",
      "accuracy       0.823445  0.823445  0.823445     0.823445\n",
      "macro avg      0.821704  0.829522  0.821989  4180.000000\n",
      "weighted avg   0.832620  0.823445  0.824500  4180.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandom Forest (Optuna-Tuned) Confusion Matrix:\")\n",
    "print(sklearn.metrics.confusion_matrix(\n",
    "    y_true=data_test_rf['label'],\n",
    "    y_pred=data_test_rf['prediction']\n",
    "))\n",
    "\n",
    "report_scores_rf = sklearn.metrics.classification_report(\n",
    "    y_true=data_test_rf['label'],\n",
    "    y_pred=data_test_rf['prediction'],\n",
    "    digits=6,\n",
    "    output_dict=True\n",
    ")\n",
    "df_score_rf = pandas.DataFrame(report_scores_rf).transpose()\n",
    "print(\"\\nRandom Forest (Optuna-Tuned) Report:\")\n",
    "print(df_score_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ad701c",
   "metadata": {},
   "source": [
    "Best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "476b9ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 800,\n",
       " 'max_depth': 13,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 10,\n",
       " 'criterion': 'entropy',\n",
       " 'max_features': 0.27802443984172714}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameter = study.best_params\n",
    "best_parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3723ac4a",
   "metadata": {},
   "source": [
    "### Best Params\n",
    "```\n",
    "'n_estimators': 800,\n",
    " 'max_depth': 13,\n",
    " 'min_samples_leaf': 2,\n",
    " 'min_samples_split': 10,\n",
    " 'criterion': 'entropy',\n",
    " 'max_features': 0.27802443984172714\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279fd3e1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
